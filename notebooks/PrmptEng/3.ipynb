{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZMmN0GI0VIu"
      },
      "source": [
        "# Data Extraction and Summarization of PDFs (Medical Reports)\n",
        "\n",
        "This notebook demonstrates how to extract and summarize data from PDF medical reports, such as chest X-ray reports related to the ChestMNIST dataset. We use Optical Character Recognition (OCR) to read PDFs, prompt Large Language Models (LLMs) for summarization and entity extraction, perform diagnosis classification, and flag uncertain or missing data.\n",
        "\n",
        "**Author**: Mohammad Rezapourian\n",
        "<br>\n",
        "**Date**: May 15, 2025\n",
        "<br>\n",
        "**License**: Apache-2.0\n",
        "\n",
        "## Table of Contents\n",
        "1. [Initial Setup](#initial-setup)\n",
        "   - [Setup for Google Colab](#setup-for-google-colab)\n",
        "   - [Setup for Offline Use](#setup-for-offline-use)\n",
        "2. [PDF Reading via OCR](#pdf-reading-via-ocr)\n",
        "   - [Loading and Processing PDFs](#loading-and-processing-pdfs)\n",
        "3. [PDF Summarization](#pdf-summarization)\n",
        "   - [Prompting for Summarization](#prompting-for-summarization)\n",
        "   - [Exercise: Summarize an Unseen PDF](#exercise-summarize-an-unseen-pdf)\n",
        "4. [Entity Extraction](#entity-extraction)\n",
        "   - [Prompting for Entity Extraction](#prompting-for-entity-extraction)\n",
        "   - [Collecting Entities into a Table](#collecting-entities-into-a-table)\n",
        "   - [Exercise: Extract Entities from a New PDF](#exercise-extract-entities-from-a-new-pdf)\n",
        "5. [Diagnosis Classification](#diagnosis-classification)\n",
        "   - [Prompting for Glioblastoma Diagnosis](#prompting-for-glioblastoma-diagnosis)\n",
        "   - [Expanding the Entity Table](#expanding-the-entity-table)\n",
        "   - [Exercise: Evaluate Classification Results](#exercise-evaluate-classification-results)\n",
        "6. [Flagging Uncertain Extractions and Missing Values](#flagging-uncertain-extractions-and-missing-values)\n",
        "   - [Prompting for Uncertainty Detection](#prompting-for-uncertainty-detection)\n",
        "7. [Conclusion](#conclusion)\n",
        "   - [References](#references)"
      ],
      "id": "rZMmN0GI0VIu"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxA-2Vzm0VIw"
      },
      "source": [
        "## Initial Setup\n",
        "\n",
        "Set up the environment for running the notebook in Google Colab or locally. We’ll install libraries for PDF processing, OCR, and data analysis."
      ],
      "id": "SxA-2Vzm0VIw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMC5rbuS0VIx"
      },
      "source": [
        "### Setup for Google Colab\n",
        "<u>Execute these code blocks only in Google Colab!</u>"
      ],
      "id": "uMC5rbuS0VIx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nd2ZHEzH0VIx"
      },
      "outputs": [],
      "source": [
        "!apt-get install -q poppler-utils tesseract-ocr\n",
        "!pip install -q pdf2image pytesseract pandas numpy matplotlib seaborn"
      ],
      "id": "nd2ZHEzH0VIx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JkRXO-OA0VIy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "%matplotlib inline\n",
        "import pdf2image\n",
        "import pytesseract\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import re"
      ],
      "id": "JkRXO-OA0VIy"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rguzpj1R0VIy"
      },
      "source": [
        "### Setup for Offline Use\n",
        "\n",
        "Ensure `poppler-utils` and `tesseract-ocr` are installed on your system. For example, on Ubuntu:\n",
        "```bash\n",
        "sudo apt-get install poppler-utils tesseract-ocr\n",
        "```\n",
        "On macOS:\n",
        "```bash\n",
        "brew install poppler tesseract\n",
        "```"
      ],
      "id": "Rguzpj1R0VIy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-S965Xr0VIy"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import pdf2image\n",
        "import pytesseract\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import re"
      ],
      "id": "f-S965Xr0VIy"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "argSK3cu0VIy"
      },
      "source": [
        "## PDF Reading via OCR\n",
        "\n",
        "We’ll read PDF medical reports using OCR to extract text, assuming the PDFs contain chest X-ray reports with patient details and findings."
      ],
      "id": "argSK3cu0VIy"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hT_MHEHG0VIy"
      },
      "source": [
        "### Loading and Processing PDFs\n",
        "\n",
        "We’ll convert PDFs to images and apply OCR to extract text. For demonstration, assume a sample PDF `report1.pdf` in `./Data/Reports/`. Users should replace it with their own PDF."
      ],
      "id": "hT_MHEHG0VIy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bT4R77N0VIy"
      },
      "outputs": [],
      "source": [
        "# Function to read PDF and extract text\n",
        "def read_pdf_ocr(pdf_path):\n",
        "    try:\n",
        "        # Convert PDF to images\n",
        "        images = pdf2image.convert_from_path(pdf_path)\n",
        "        text = ''\n",
        "        for img in images:\n",
        "            # Apply OCR\n",
        "            text += pytesseract.image_to_string(img) + '\\n'\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f'Error reading {pdf_path}: {e}')\n",
        "        return None\n",
        "\n",
        "# Example PDF\n",
        "pdf_path = './Data/Reports/report1.pdf'\n",
        "text = read_pdf_ocr(pdf_path)\n",
        "if text:\n",
        "    print('Extracted text (first 500 characters):')\n",
        "    print(text[:500])\n",
        "else:\n",
        "    print('Failed to extract text. Please check the PDF path and OCR setup.')"
      ],
      "id": "3bT4R77N0VIy"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xySFwlAC0VIy"
      },
      "source": [
        "**Note**: Replace `report1.pdf` with your PDF file. Ensure the `./Data/Reports/` directory exists. If no PDF is available, use the sample text below for testing:\n",
        "```\n",
        "Patient Report\n",
        "Name: John Doe\n",
        "Age: 55\n",
        "Gender: Male\n",
        "Date: 2025-01-10\n",
        "Findings: Chest X-ray shows bilateral infiltrates and pleural effusion. No evidence of glioblastoma. Suspected pneumonia and pulmonary edema.\n",
        "Diagnosis: Pneumonia, Effusion\n",
        "```\n",
        "Save this as `sample_report.txt` and modify the code to read it if needed."
      ],
      "id": "xySFwlAC0VIy"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QebDT0nE0VIz"
      },
      "source": [
        "## PDF Summarization\n",
        "\n",
        "We’ll prompt an LLM to summarize the PDF content, extracting key information like age, gender, and report summary."
      ],
      "id": "QebDT0nE0VIz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsni_xpk0VIz"
      },
      "source": [
        "### Prompting for Summarization\n",
        "\n",
        "**Prompt Template**:\n",
        "```\n",
        "Summarize the following medical report. Extract the patient's age, gender, and a concise summary of the findings. Format the output as:\n",
        "- Age: [value]\n",
        "- Gender: [value]\n",
        "- Summary: [text]\n",
        "\n",
        "Report text:\n",
        "[insert extracted text]\n",
        "```\n",
        "\n",
        "**Simulated LLM Response** (for `sample_report.txt`):\n",
        "```plaintext\n",
        "- Age: 55\n",
        "- Gender: Male\n",
        "- Summary: The chest X-ray indicates bilateral infiltrates and pleural effusion, suggestive of pneumonia and pulmonary edema. No glioblastoma observed.\n",
        "```"
      ],
      "id": "qsni_xpk0VIz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIFq6iw90VIz"
      },
      "outputs": [],
      "source": [
        "# Function to simulate LLM summarization\n",
        "def summarize_report(text):\n",
        "    # Simulated LLM logic (replace with actual LLM call if available)\n",
        "    summary = {'Age': None, 'Gender': None, 'Summary': ''}\n",
        "    # Extract age\n",
        "    age_match = re.search(r'Age:\\s*(\\d+)', text, re.IGNORECASE)\n",
        "    if age_match:\n",
        "        summary['Age'] = int(age_match.group(1))\n",
        "    # Extract gender\n",
        "    gender_match = re.search(r'Gender:\\s*(Male|Female|Other)', text, re.IGNORECASE)\n",
        "    if gender_match:\n",
        "        summary['Gender'] = gender_match.group(1)\n",
        "    # Extract findings\n",
        "    findings_match = re.search(r'Findings:\\s*(.+?)(?:Diagnosis|$)', text, re.IGNORECASE | re.DOTALL)\n",
        "    if findings_match:\n",
        "        summary['Summary'] = findings_match.group(1).strip()\n",
        "    return summary\n",
        "\n",
        "# Summarize sample report\n",
        "if text:\n",
        "    summary = summarize_report(text)\n",
        "    print('Summary:')\n",
        "    for key, value in summary.items():\n",
        "        print(f'{key}: {value}')"
      ],
      "id": "FIFq6iw90VIz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "as-ubm6U0VIz"
      },
      "source": [
        "**Note**: Replace the simulated logic with an actual LLM call."
      ],
      "id": "as-ubm6U0VIz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQzGhhfx0VIz"
      },
      "source": [
        "### Exercise: Summarize an Unseen PDF\n",
        "\n",
        "**Task**: Apply the summarization function to a new PDF (`report2.pdf`) and verify the output.\n",
        "\n",
        "**Code**:\n"
      ],
      "id": "pQzGhhfx0VIz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGrte0eq0VIz"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "new_pdf_path = './Data/Reports/report2.pdf'\n",
        "new_text = read_pdf_ocr(new_pdf_path)\n",
        "if new_text:\n",
        "    new_summary = summarize_report(new_text)\n",
        "    print('Summary of report2.pdf:')\n",
        "    for key, value in new_summary.items():\n",
        "        print(f'{key}: {value}')\n",
        "else:\n",
        "    print('Failed to read report2.pdf.')"
      ],
      "id": "ZGrte0eq0VIz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxoYkROz0VIz"
      },
      "source": [
        "**Solution**: The code reads a new PDF, extracts text via OCR, and summarizes it. Verify the output by checking the extracted age, gender, and summary against the PDF content. If no PDF is available, test with a new sample text."
      ],
      "id": "WxoYkROz0VIz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7wlsS-j0VIz"
      },
      "source": [
        "## Entity Extraction\n",
        "\n",
        "We’ll extract entities like patient name, diagnosis, and findings from the PDF and store them in a table."
      ],
      "id": "o7wlsS-j0VIz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEQ_-KRV0VIz"
      },
      "source": [
        "### Prompting for Entity Extraction\n",
        "\n",
        "**Prompt Template**:\n",
        "```\n",
        "Extract the following entities from the medical report:\n",
        "- Patient Name\n",
        "- Diagnosis\n",
        "- Findings\n",
        "- Date\n",
        "Return the results in a JSON format:\n",
        "{\n",
        "  \"Patient Name\": \"value\",\n",
        "  \"Diagnosis\": \"value\",\n",
        "  \"Findings\": \"value\",\n",
        "  \"Date\": \"value\"\n",
        "}\n",
        "\n",
        "Report text:\n",
        "[insert extracted text]\n",
        "```\n",
        "\n",
        "**Simulated LLM Response**:\n",
        "```json\n",
        "{\n",
        "  \"Patient Name\": \"John Doe\",\n",
        "  \"Diagnosis\": \"Pneumonia, Effusion\",\n",
        "  \"Findings\": \"Bilateral infiltrates and pleural effusion. No glioblastoma.\",\n",
        "  \"Date\": \"2025-01-10\"\n",
        "}\n",
        "```"
      ],
      "id": "pEQ_-KRV0VIz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QY8BSvoz0VIz"
      },
      "outputs": [],
      "source": [
        "# Function to simulate entity extraction\n",
        "def extract_entities(text):\n",
        "    entities = {'Patient Name': None, 'Diagnosis': None, 'Findings': None, 'Date': None}\n",
        "    # Name\n",
        "    name_match = re.search(r'Name:\\s*([A-Za-z\\s]+)', text, re.IGNORECASE)\n",
        "    if name_match:\n",
        "        entities['Patient Name'] = name_match.group(1).strip()\n",
        "    # Diagnosis\n",
        "    diag_match = re.search(r'Diagnosis:\\s*(.+)', text, re.IGNORECASE)\n",
        "    if diag_match:\n",
        "        entities['Diagnosis'] = diag_match.group(1).strip()\n",
        "    # Findings\n",
        "    findings_match = re.search(r'Findings:\\s*(.+?)(?:Diagnosis|$)', text, re.IGNORECASE | re.DOTALL)\n",
        "    if findings_match:\n",
        "        entities['Findings'] = findings_match.group(1).strip()\n",
        "    # Date\n",
        "    date_match = re.search(r'Date:\\s*(\\d{4}-\\d{2}-\\d{2})', text, re.IGNORECASE)\n",
        "    if date_match:\n",
        "        entities['Date'] = date_match.group(1)\n",
        "    return entities\n",
        "\n",
        "# Extract entities\n",
        "if text:\n",
        "    entities = extract_entities(text)\n",
        "    print('Extracted entities:')\n",
        "    print(entities)"
      ],
      "id": "QY8BSvoz0VIz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53CwByqq0VIz"
      },
      "source": [
        "### Collecting Entities into a Table\n",
        "\n",
        "Store entities in a pandas DataFrame for further analysis."
      ],
      "id": "53CwByqq0VIz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25Mxzs9l0VI0"
      },
      "outputs": [],
      "source": [
        "# Create DataFrame\n",
        "if text:\n",
        "    entity_df = pd.DataFrame([entities])\n",
        "    print('Entity table:')\n",
        "    print(entity_df)\n",
        "else:\n",
        "    entity_df = pd.DataFrame(columns=['Patient Name', 'Diagnosis', 'Findings', 'Date'])"
      ],
      "id": "25Mxzs9l0VI0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5EvYJjA0VI0"
      },
      "source": [
        "### Exercise: Extract Entities from a New PDF\n",
        "\n",
        "**Task**: Extract entities from `report2.pdf` and add them to the DataFrame.\n",
        "\n",
        "**Code**:\n"
      ],
      "id": "z5EvYJjA0VI0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIaLqMAv0VI0"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "new_entities = extract_entities(new_text)\n",
        "if new_entities:\n",
        "    new_entity_df = pd.DataFrame([new_entities])\n",
        "    entity_df = pd.concat([entity_df, new_entity_df], ignore_index=True)\n",
        "    print('Updated entity table:')\n",
        "    print(entity_df)\n",
        "else:\n",
        "    print('Failed to extract entities from report2.pdf.')"
      ],
      "id": "SIaLqMAv0VI0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnB1Y4zo0VI0"
      },
      "source": [
        "**Solution**: The code extracts entities from the new PDF and appends them to the DataFrame. Verify the table for accuracy against the PDF content."
      ],
      "id": "AnB1Y4zo0VI0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdypCYSt0VI0"
      },
      "source": [
        "## Diagnosis Classification\n",
        "\n",
        "Classify whether the patient has glioblastoma based on the findings."
      ],
      "id": "zdypCYSt0VI0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HCUpeIQ0VI0"
      },
      "source": [
        "### Prompting for Glioblastoma Diagnosis\n",
        "\n",
        "**Prompt Template**:\n",
        "```\n",
        "Based on the findings in the medical report, does the patient have glioblastoma? Answer Yes or No.\n",
        "\n",
        "Findings:\n",
        "[insert findings]\n",
        "```\n",
        "\n",
        "**Simulated LLM Response**:\n",
        "```plaintext\n",
        "No\n",
        "```"
      ],
      "id": "4HCUpeIQ0VI0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FkF2ny60VI0"
      },
      "outputs": [],
      "source": [
        "# Function to simulate glioblastoma classification\n",
        "def classify_glioblastoma(findings):\n",
        "    # Simulated LLM logic\n",
        "    if findings and 'glioblastoma' in findings.lower():\n",
        "        return 'Yes'\n",
        "    return 'No'\n",
        "\n",
        "# Apply classification\n",
        "if not entity_df.empty:\n",
        "    entity_df['Glioblastoma'] = entity_df['Findings'].apply(classify_glioblastoma)\n",
        "    print('Updated entity table with glioblastoma classification:')\n",
        "    print(entity_df)"
      ],
      "id": "-FkF2ny60VI0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCntuWcr0VI0"
      },
      "source": [
        "### Expanding the Entity Table\n",
        "\n",
        "The table now includes a `Glioblastoma` column with Yes/No values."
      ],
      "id": "FCntuWcr0VI0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_TCO_q10VI0"
      },
      "source": [
        "### Exercise: Evaluate Classification Results\n",
        "\n",
        "**Task**: Evaluate the glioblastoma classification by checking the findings for false positives/negatives.\n",
        "\n",
        "**Code**:\n"
      ],
      "id": "f_TCO_q10VI0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJpH-WTW0VI0"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "if not entity_df.empty:\n",
        "    print('Evaluation of glioblastoma classification:')\n",
        "    for idx, row in entity_df.iterrows():\n",
        "        print(f'Patient: {row[\"Patient Name\"]}')\n",
        "        print(f'Findings: {row[\"Findings\"]}')\n",
        "        print(f'Classified as Glioblastoma: {row[\"Glioblastoma\"]}')\n",
        "        print('Correct? (Manual check required)')\n",
        "        print('-' * 50)\n",
        "else:\n",
        "    print('No data to evaluate.')"
      ],
      "id": "NJpH-WTW0VI0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_perywi0VI0"
      },
      "source": [
        "**Solution**: Manually review the findings and classification. For example, if findings mention \"no glioblastoma,\" the classification should be \"No.\" Flag any mismatches for further LLM prompt refinement."
      ],
      "id": "t_perywi0VI0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3I6U2IGx0VI0"
      },
      "source": [
        "## Flagging Uncertain Extractions and Missing Values\n",
        "\n",
        "Prompt the LLM to identify uncertain extractions or missing values in the entities."
      ],
      "id": "3I6U2IGx0VI0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJ7-MkzF0VI1"
      },
      "source": [
        "### Prompting for Uncertainty Detection\n",
        "\n",
        "**Prompt Template**:\n",
        "```\n",
        "Review the extracted entities from the medical report. Flag any uncertain extractions (e.g., ambiguous text) or missing values. Provide a list of issues in the format:\n",
        "- Entity: [name], Issue: [description]\n",
        "\n",
        "Entities:\n",
        "[insert entities JSON]\n",
        "\n",
        "Report text:\n",
        "[insert extracted text]\n",
        "```\n",
        "\n",
        "**Simulated LLM Response**:\n",
        "```plaintext\n",
        "- Entity: Patient Name, Issue: None\n",
        "- Entity: Diagnosis, Issue: None\n",
        "- Entity: Findings, Issue: None\n",
        "- Entity: Date, Issue: None\n",
        "```"
      ],
      "id": "aJ7-MkzF0VI1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXY2I32I0VI1"
      },
      "outputs": [],
      "source": [
        "# Function to flag uncertain or missing values\n",
        "def flag_uncertain_entities(entities, text):\n",
        "    issues = []\n",
        "    for key, value in entities.items():\n",
        "        if value is None:\n",
        "            issues.append(f'Entity: {key}, Issue: Missing value')\n",
        "        elif key in ['Patient Name', 'Diagnosis', 'Findings', 'Date']:\n",
        "            # Check for ambiguous or short values\n",
        "            if len(str(value)) < 3:\n",
        "                issues.append(f'Entity: {key}, Issue: Potentially ambiguous (too short: {value})')\n",
        "    return issues\n",
        "\n",
        "# Flag issues\n",
        "if text and entities:\n",
        "    issues = flag_uncertain_entities(entities, text)\n",
        "    print('Uncertainty and missing value issues:')\n",
        "    if issues:\n",
        "        for issue in issues:\n",
        "            print(issue)\n",
        "    else:\n",
        "        print('No issues detected.')"
      ],
      "id": "vXY2I32I0VI1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUCwzXPv0VI1"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "This notebook demonstrated comprehensive data extraction and summarization from PDF medical reports using OCR, LLM prompting, and pandas. We summarized reports, extracted entities, classified glioblastoma, and flagged uncertainties. Exercises reinforced these skills with practical applications. The DataFrame enables further data science tasks, such as statistical analysis or machine learning.\n",
        "\n",
        "### References\n",
        "- Tesseract OCR: https://github.com/tesseract-ocr/tesseract\n",
        "- PDF2Image: https://github.com/oschwartz10612/poppler-python\n",
        "- Pandas Documentation: https://pandas.pydata.org/docs/\n",
        "- ChestMNIST Context: https://www.nih.gov/news-events/news-releases/nih-clinical-center-provides-one-largest-publicly-available-chest-x-ray-datasets-scientific-community"
      ],
      "id": "cUCwzXPv0VI1"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}