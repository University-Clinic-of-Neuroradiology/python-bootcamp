{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHkrQYpy134K"
      },
      "source": [
        "# Working with Research Papers (Chest X-ray Analysis)\n",
        "\n",
        "This notebook demonstrates how to process a research paper PDF, summarize its content, and ask specific questions to extract key insights. We focus on a hypothetical paper related to the ChestMNIST dataset, 'Advances in Chest X-ray Classification Using ChestMNIST.' The notebook uses Optical Character Recognition (OCR) to read PDFs, prompts Large Language Models (LLMs) for summarization and question-answering, and includes exercises to apply these techniques to new papers.\n",
        "\n",
        "**Author**: Mohammad Rezapourian\n",
        "<br>\n",
        "**Date**: May 13, 2025\n",
        "<br>\n",
        "**License**: Apache-2.0\n",
        "\n",
        "## Table of Contents\n",
        "1. [Initial Setup](#initial-setup)\n",
        "   - [Setup for Google Colab](#setup-for-google-colab)\n",
        "   - [Setup for Offline Use](#setup-for-offline-use)\n",
        "2. [PDF Reading via OCR](#pdf-reading-via-ocr)\n",
        "   - [Loading and Processing the Research Paper](#loading-and-processing-the-research-paper)\n",
        "3. [Paper Summarization](#paper-summarization)\n",
        "   - [Prompting for Summarization](#prompting-for-summarization)\n",
        "   - [Exercise: Summarize a New Paper](#exercise-summarize-a-new-paper)\n",
        "4. [Asking Specific Questions](#asking-specific-questions)\n",
        "   - [Prompting for Question-Answering](#prompting-for-question-answering)\n",
        "   - [Storing Answers in a Table](#storing-answers-in-a-table)\n",
        "   - [Exercise: Ask Questions on a New Paper](#exercise-ask-questions-on-a-new-paper)\n",
        "5. [Conclusion](#conclusion)\n",
        "   - [References](#references)"
      ],
      "id": "zHkrQYpy134K"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0ckJ2B_134N"
      },
      "source": [
        "## Initial Setup\n",
        "\n",
        "Set up the environment for running the notebook in Google Colab or locally. We’ll install libraries for PDF processing, OCR, and data analysis."
      ],
      "id": "O0ckJ2B_134N"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Faht9Lmw134N"
      },
      "source": [
        "### Setup for Google Colab\n",
        "<u>Execute these code blocks only in Google Colab!</u>"
      ],
      "id": "Faht9Lmw134N"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6XfJWHp134N"
      },
      "outputs": [],
      "source": [
        "!apt-get install -q poppler-utils tesseract-ocr\n",
        "!pip install -q pdf2image pytesseract pandas numpy matplotlib seaborn"
      ],
      "id": "q6XfJWHp134N"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zckiGzp1134O"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "%matplotlib inline\n",
        "import pdf2image\n",
        "import pytesseract\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import re"
      ],
      "id": "zckiGzp1134O"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wqQvhk6134O"
      },
      "source": [
        "### Setup for Offline Use\n",
        "\n",
        "Ensure `poppler-utils` and `tesseract-ocr` are installed. For example, on Ubuntu:\n",
        "```bash\n",
        "sudo apt-get install poppler-utils tesseract-ocr\n",
        "```\n",
        "On macOS:\n",
        "```bash\n",
        "brew install poppler tesseract\n",
        "```"
      ],
      "id": "5wqQvhk6134O"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-P698eT134O"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import pdf2image\n",
        "import pytesseract\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import re"
      ],
      "id": "w-P698eT134O"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3Wg6Toa134P"
      },
      "source": [
        "## PDF Reading via OCR\n",
        "\n",
        "We’ll read the research paper PDF using OCR to extract text, assuming it contains details about chest X-ray classification using the ChestMNIST dataset."
      ],
      "id": "S3Wg6Toa134P"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rNbpTFY134P"
      },
      "source": [
        "### Loading and Processing the Research Paper\n",
        "\n",
        "We’ll convert the PDF to images and apply OCR to extract text. For demonstration, assume a sample PDF `paper1.pdf` in `./Data/Papers/`. Users should replace it with their own research paper PDF."
      ],
      "id": "0rNbpTFY134P"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "si6gje1d134P"
      },
      "outputs": [],
      "source": [
        "# Function to read PDF and extract text\n",
        "def read_pdf_ocr(pdf_path):\n",
        "    try:\n",
        "        images = pdf2image.convert_from_path(pdf_path)\n",
        "        text = ''\n",
        "        for img in images:\n",
        "            text += pytesseract.image_to_string(img) + '\\n'\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f'Error reading {pdf_path}: {e}')\n",
        "        return None\n",
        "\n",
        "# Example PDF\n",
        "pdf_path = './Data/Papers/paper1.pdf'\n",
        "text = read_pdf_ocr(pdf_path)\n",
        "if text:\n",
        "    print('Extracted text (first 500 characters):')\n",
        "    print(text[:500])\n",
        "else:\n",
        "    print('Failed to extract text. Please check the PDF path and OCR setup.')"
      ],
      "id": "si6gje1d134P"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVt4EyRW134P"
      },
      "source": [
        "**Note**: Replace `paper1.pdf` with your research paper PDF. Ensure the `./Data/Papers/` directory exists. If no PDF is available, use the sample text below for testing:\n",
        "```\n",
        "Title: Advances in Chest X-ray Classification Using ChestMNIST\n",
        "Authors: Jane Smith, John Lee\n",
        "Abstract: This paper presents a novel deep learning model for multi-label classification of chest X-rays using the ChestMNIST dataset. The dataset includes 112,120 images with 14 disease labels. Our convolutional neural network (CNN) achieves an accuracy of 92% on the test set, outperforming baseline models.\n",
        "Introduction: Chest X-rays are critical for diagnosing conditions like pneumonia and effusion. The ChestMNIST dataset provides a standardized benchmark.\n",
        "Methods: We used a CNN with ResNet-50 architecture, trained on 78,468 training images.\n",
        "Results: The model achieved high precision for pneumonia (0.95) and effusion (0.93).\n",
        "Conclusion: Our approach demonstrates the potential of deep learning for automated diagnosis.\n",
        "```\n",
        "Save this as `sample_paper.txt` and modify the code to read it if needed."
      ],
      "id": "lVt4EyRW134P"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehToM2tT134P"
      },
      "source": [
        "## Paper Summarization\n",
        "\n",
        "We’ll prompt an LLM to summarize the research paper, extracting key details like the title, authors, objectives, methods, and findings."
      ],
      "id": "ehToM2tT134P"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8VU3hsY134P"
      },
      "source": [
        "### Prompting for Summarization\n",
        "\n",
        "**Prompt Template**:\n",
        "```\n",
        "Summarize the following research paper. Extract the following details:\n",
        "- Title\n",
        "- Authors\n",
        "- Objectives\n",
        "- Methods\n",
        "- Key Findings\n",
        "Format the output as:\n",
        "- Title: [value]\n",
        "- Authors: [value]\n",
        "- Objectives: [value]\n",
        "- Methods: [value]\n",
        "- Key Findings: [value]\n",
        "\n",
        "Paper text:\n",
        "[insert extracted text]\n",
        "```\n",
        "\n",
        "**Simulated LLM Response** (for `sample_paper.txt`):\n",
        "```plaintext\n",
        "- Title: Advances in Chest X-ray Classification Using ChestMNIST\n",
        "- Authors: Jane Smith, John Lee\n",
        "- Objectives: Develop a deep learning model for multi-label classification of chest X-rays using the ChestMNIST dataset.\n",
        "- Methods: Utilized a convolutional neural network with ResNet-50 architecture, trained on 78,468 images.\n",
        "- Key Findings: Achieved 92% test accuracy, with high precision for pneumonia (0.95) and effusion (0.93).\n",
        "```"
      ],
      "id": "h8VU3hsY134P"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TuHdFAG4134P"
      },
      "outputs": [],
      "source": [
        "# Function to simulate LLM summarization\n",
        "def summarize_paper(text):\n",
        "    summary = {'Title': None, 'Authors': None, 'Objectives': None, 'Methods': None, 'Key Findings': None}\n",
        "    # Title\n",
        "    title_match = re.search(r'Title:\\s*(.+)', text, re.IGNORECASE)\n",
        "    if title_match:\n",
        "        summary['Title'] = title_match.group(1).strip()\n",
        "    # Authors\n",
        "    authors_match = re.search(r'Authors:\\s*(.+)', text, re.IGNORECASE)\n",
        "    if authors_match:\n",
        "        summary['Authors'] = authors_match.group(1).strip()\n",
        "    # Objectives\n",
        "    obj_match = re.search(r'Abstract:\\s*(.+?)(?:Introduction|$)', text, re.IGNORECASE | re.DOTALL)\n",
        "    if obj_match:\n",
        "        summary['Objectives'] = obj_match.group(1).strip()\n",
        "    # Methods\n",
        "    methods_match = re.search(r'Methods:\\s*(.+?)(?:Results|$)', text, re.IGNORECASE | re.DOTALL)\n",
        "    if methods_match:\n",
        "        summary['Methods'] = methods_match.group(1).strip()\n",
        "    # Key Findings\n",
        "    findings_match = re.search(r'Results:\\s*(.+?)(?:Conclusion|$)', text, re.IGNORECASE | re.DOTALL)\n",
        "    if findings_match:\n",
        "        summary['Key Findings'] = findings_match.group(1).strip()\n",
        "    return summary\n",
        "\n",
        "# Summarize sample paper\n",
        "if text:\n",
        "    summary = summarize_paper(text)\n",
        "    print('Summary:')\n",
        "    for key, value in summary.items():\n",
        "        print(f'{key}: {value}')"
      ],
      "id": "TuHdFAG4134P"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aOaNsPO134Q"
      },
      "source": [
        "### Exercise: Summarize a New Paper\n",
        "\n",
        "**Task**: Apply the summarization function to a new paper (`paper2.pdf`) and verify the output.\n",
        "\n",
        "**Code**:\n"
      ],
      "id": "9aOaNsPO134Q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQgEKPZF134Q"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "new_pdf_path = './Data/Papers/paper2.pdf'\n",
        "new_text = read_pdf_ocr(new_pdf_path)\n",
        "if new_text:\n",
        "    new_summary = summarize_paper(new_text)\n",
        "    print('Summary of paper2.pdf:')\n",
        "    for key, value in new_summary.items():\n",
        "        print(f'{key}: {value}')\n",
        "else:\n",
        "    print('Failed to read paper2.pdf.')"
      ],
      "id": "PQgEKPZF134Q"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-YSnRNG134Q"
      },
      "source": [
        "**Solution**: The code reads a new PDF, extracts text via OCR, and summarizes it. Verify the output by checking the extracted fields against the paper’s content. If no PDF is available, test with a new sample text."
      ],
      "id": "v-YSnRNG134Q"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2G4ribc134Q"
      },
      "source": [
        "## Asking Specific Questions\n",
        "\n",
        "We’ll ask targeted questions about the paper to extract specific insights, such as dataset details, model performance, and limitations."
      ],
      "id": "P2G4ribc134Q"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ypsKBjd134Q"
      },
      "source": [
        "### Prompting for Question-Answering\n",
        "\n",
        "**Questions**:\n",
        "1. What is the size of the ChestMNIST dataset used in the study?\n",
        "2. What is the accuracy of the proposed model on the test set?\n",
        "3. What are the main limitations of the study?\n",
        "\n",
        "**Prompt Template**:\n",
        "```\n",
        "Answer the following questions based on the research paper. Provide concise answers in the format:\n",
        "- Question: [question]\n",
        "- Answer: [answer]\n",
        "\n",
        "Questions:\n",
        "1. What is the size of the ChestMNIST dataset used in the study?\n",
        "2. What is the accuracy of the proposed model on the test set?\n",
        "3. What are the main limitations of the study?\n",
        "\n",
        "Paper text:\n",
        "[insert extracted text]\n",
        "```\n",
        "\n",
        "**Simulated LLM Response**:\n",
        "```plaintext\n",
        "- Question: What is the size of the ChestMNIST dataset used in the study?\n",
        "- Answer: The ChestMNIST dataset includes 112,120 images.\n",
        "- Question: What is the accuracy of the proposed model on the test set?\n",
        "- Answer: The model achieves an accuracy of 92% on the test set.\n",
        "- Question: What are the main limitations of the study?\n",
        "- Answer: The study does not address class imbalance and lacks generalizability to other datasets.\n",
        "```"
      ],
      "id": "3ypsKBjd134Q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wgb5ywID134Q"
      },
      "outputs": [],
      "source": [
        "# Function to simulate question-answering\n",
        "def answer_questions(text):\n",
        "    answers = {\n",
        "        'What is the size of the ChestMNIST dataset used in the study?': None,\n",
        "        'What is the accuracy of the proposed model on the test set?': None,\n",
        "        'What are the main limitations of the study?': None\n",
        "    }\n",
        "    # Dataset size\n",
        "    size_match = re.search(r'ChestMNIST dataset.*?(\\d+,\\d+)', text, re.IGNORECASE)\n",
        "    if size_match:\n",
        "        answers['What is the size of the ChestMNIST dataset used in the study?'] = f'The ChestMNIST dataset includes {size_match.group(1)} images.'\n",
        "    # Accuracy\n",
        "    acc_match = re.search(r'accuracy of\\s*(\\d+%)', text, re.IGNORECASE)\n",
        "    if acc_match:\n",
        "        answers['What is the accuracy of the proposed model on the test set?'] = f'The model achieves an accuracy of {acc_match.group(1)} on the test set.'\n",
        "    # Limitations\n",
        "    lim_match = re.search(r'(limitation|challenge).*?((?:not address|lack).*?)(?:\\.|$)', text, re.IGNORECASE | re.DOTALL)\n",
        "    if lim_match:\n",
        "        answers['What are the main limitations of the study?'] = lim_match.group(2).strip()\n",
        "    return answers\n",
        "\n",
        "# Answer questions\n",
        "if text:\n",
        "    answers = answer_questions(text)\n",
        "    print('Answers to specific questions:')\n",
        "    for question, answer in answers.items():\n",
        "        print(f'Question: {question}')\n",
        "        print(f'Answer: {answer}')"
      ],
      "id": "Wgb5ywID134Q"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMCOFS2X134Q"
      },
      "source": [
        "### Storing Answers in a Table\n",
        "\n",
        "Store the questions and answers in a pandas DataFrame for further analysis."
      ],
      "id": "oMCOFS2X134Q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AceCS32S134Q"
      },
      "outputs": [],
      "source": [
        "# Create DataFrame\n",
        "if text:\n",
        "    qa_df = pd.DataFrame([\n",
        "        {'Question': q, 'Answer': a} for q, a in answers.items()\n",
        "    ])\n",
        "    print('Question-Answer table:')\n",
        "    print(qa_df)\n",
        "else:\n",
        "    qa_df = pd.DataFrame(columns=['Question', 'Answer'])"
      ],
      "id": "AceCS32S134Q"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObeZ7dvg134Q"
      },
      "source": [
        "### Exercise: Ask Questions on a New Paper\n",
        "\n",
        "**Task**: Apply the question-answering function to a new paper (`paper2.pdf`) and add the answers to the DataFrame.\n",
        "\n",
        "**Code**:\n"
      ],
      "id": "ObeZ7dvg134Q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7E8qIQx134Q"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "new_answers = answer_questions(new_text)\n",
        "if new_answers:\n",
        "    new_qa_df = pd.DataFrame([\n",
        "        {'Question': q, 'Answer': a} for q, a in new_answers.items()\n",
        "    ])\n",
        "    qa_df = pd.concat([qa_df, new_qa_df], ignore_index=True)\n",
        "    print('Updated question-answer table:')\n",
        "    print(qa_df)\n",
        "else:\n",
        "    print('Failed to answer questions for paper2.pdf.')"
      ],
      "id": "r7E8qIQx134Q"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxOqLLOV134Q"
      },
      "source": [
        "**Solution**: The code extracts answers from the new paper and appends them to the DataFrame. Verify the answers against the paper’s content to ensure accuracy."
      ],
      "id": "NxOqLLOV134Q"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ntRfyor134R"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "This notebook demonstrated how to process a research paper PDF using OCR, summarize its content, and answer specific questions to extract key insights. We focused on a paper related to the ChestMNIST dataset, summarizing its objectives, methods, and findings, and addressing targeted questions about dataset size, model performance, and limitations. The DataFrame enables further analysis, such as comparing multiple papers.\n",
        "\n",
        "### References\n",
        "- Tesseract OCR: https://github.com/tesseract-ocr/tesseract\n",
        "- PDF2Image: https://github.com/oschwartz10612/poppler-python\n",
        "- Pandas Documentation: https://pandas.pydata.org/docs/\n",
        "- ChestMNIST Dataset: https://www.nih.gov/news-events/news-releases/nih-clinical-center-provides-one-largest-publicly-available-chest-x-ray-datasets-scientific-community"
      ],
      "id": "7ntRfyor134R"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}