{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHCpW4AevnyJ"
      },
      "source": [
        "# Natural-Language Queries on Tabular Data (Chest X-ray Dataset)\n",
        "\n",
        "This notebook demonstrates how to perform natural-language queries on the ChestMNIST dataset, a collection of chest X-ray images with multi-label binary classifications for 14 medical conditions. We will explore the dataset, use Chain-of-Thought (CoT) reasoning to answer queries, verify results, and provide exercises to double-check findings using Pandas. The notebook is designed to be run step-by-step.\n",
        "\n",
        "**Author**: Mohammad Rezapourian\n",
        "<br>\n",
        "**First version**: May 12, 2025\n",
        "<br>\n",
        "**License**: Apache-2.0\n",
        "\n",
        "## Table of Contents\n",
        "1. [Initial Setup](#initial-setup)\n",
        "   - [Setup for Google Colab](#setup-for-google-colab)\n",
        "   - [Setup for Offline Use](#setup-for-offline-use)\n",
        "2. [Data Loading and Exploration](#data-loading-and-exploration)\n",
        "   - [Loading the ChestMNIST Dataset](#loading-the-chestmnist-dataset)\n",
        "   - [Natural-Language Query Prompts](#natural-language-query-prompts)\n",
        "   - [Visualizing Data](#visualizing-data)\n",
        "3. [Chain-of-Thought Reasoning and Verification](#chain-of-thought-reasoning-and-verification)\n",
        "   - [Query 1: Distribution of Labels](#query-1-distribution-of-labels)\n",
        "   - [Query 2: Healthy vs. Diseased Samples](#query-2-healthy-vs-diseased-samples)\n",
        "   - [Query 3: Most Common Co-occurring Conditions](#query-3-most-common-co-occurring-conditions)\n",
        "4. [Exercises: Double-Checking with Pandas](#exercises-double-checking-with-pandas)\n",
        "   - [Exercise 1: Verify Label Distribution](#exercise-1-verify-label-distribution)\n",
        "   - [Exercise 2: Verify Healthy Samples](#exercise-2-verify-healthy-samples)\n",
        "5. [Conclusion](#conclusion)\n",
        "   - [References](#references)"
      ],
      "id": "mHCpW4AevnyJ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pblyxjsBvnyL"
      },
      "source": [
        "## Initial Setup\n",
        "\n",
        "This section sets up the environment for running the notebook, either in Google Colab or offline. Execute the appropriate setup based on your environment."
      ],
      "id": "pblyxjsBvnyL"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mbvW_K-vnyL"
      },
      "source": [
        "### Setup for Google Colab\n",
        "<u>Execute these code blocks only in Google Colab!</u>"
      ],
      "id": "6mbvW_K-vnyL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjlSzPMOvnyL"
      },
      "outputs": [],
      "source": [
        "!wget -q -O - https://github.com/University-Clinic-of-Neuroradiology/python-bootcamp/archive/refs/heads/main.tar.gz | tar -xzf - --strip-components=2 python-bootcamp-main/notebooks/DeepLearning"
      ],
      "id": "fjlSzPMOvnyL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDp_jUE1vnyM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "\n",
        "sys.path.insert(0, 'DeepLearning')\n",
        "os.chdir(sys.path[0])"
      ],
      "id": "qDp_jUE1vnyM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nRd9hDuvnyM"
      },
      "outputs": [],
      "source": [
        "%pip install -q ipympl numpy matplotlib seaborn pandas"
      ],
      "id": "8nRd9hDuvnyM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_KFd-aIvnyM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd"
      ],
      "id": "d_KFd-aIvnyM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTiA3cGhvnyM"
      },
      "source": [
        "### Setup for Offline Use"
      ],
      "id": "RTiA3cGhvnyM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBxP0LZ1vnyN"
      },
      "outputs": [],
      "source": [
        "%matplotlib widget"
      ],
      "id": "tBxP0LZ1vnyN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KQlCoDBvnyN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd"
      ],
      "id": "_KQlCoDBvnyN"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEAPfs7vvnyN"
      },
      "source": [
        "## Data Loading and Exploration\n",
        "\n",
        "We will load the ChestMNIST dataset and explore its structure using natural-language queries. The dataset contains chest X-ray images (28x28 grayscale) and multi-label binary classifications for 14 medical conditions."
      ],
      "id": "oEAPfs7vvnyN"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgIOjwiQvnyN"
      },
      "source": [
        "### Loading the ChestMNIST Dataset"
      ],
      "id": "pgIOjwiQvnyN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVhemH2NvnyN"
      },
      "outputs": [],
      "source": [
        "# Define the path to the dataset\n",
        "data_path = './Data/ChestMNIST/chestmnist.npz'\n",
        "\n",
        "# Load the dataset\n",
        "ds = np.load(data_path)\n",
        "print('Content of dataset:', list(ds.keys()))"
      ],
      "id": "aVhemH2NvnyN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myjudGBfvnyN"
      },
      "outputs": [],
      "source": [
        "# Display dataset sizes\n",
        "print(f\"Number of training images: {len(ds['train_images'])} and labels: {len(ds['train_labels'])}\")\n",
        "print(f\"Number of validation images: {len(ds['val_images'])} and labels: {len(ds['val_labels'])}\")\n",
        "print(f\"Number of testing images: {len(ds['test_images'])} and labels: {len(ds['test_labels'])}\")"
      ],
      "id": "myjudGBfvnyN"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsfpbvNivnyN"
      },
      "source": [
        "The dataset is split into training, validation, and testing sets. Each image is 28x28 pixels, and labels are binary vectors indicating the presence (1) or absence (0) of 14 conditions:\n",
        "- 0: Atelectasis\n",
        "- 1: Cardiomegaly\n",
        "- 2: Effusion\n",
        "- 3: Infiltration\n",
        "- 4: Mass\n",
        "- 5: Nodule\n",
        "- 6: Pneumonia\n",
        "- 7: Pneumothorax\n",
        "- 8: Consolidation\n",
        "- 9: Edema\n",
        "- 10: Emphysema\n",
        "- 11: Fibrosis\n",
        "- 12: Pleural Thickening\n",
        "- 13: Hernia"
      ],
      "id": "ZsfpbvNivnyN"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ReAgbkSvnyN"
      },
      "source": [
        "### Natural-Language Query Prompts\n",
        "\n",
        "We will simulate natural-language queries to explore the dataset. Example queries include:\n",
        "- \"How are the labels distributed across the training set?\"\n",
        "- \"What percentage of samples are healthy (no conditions)?\"\n",
        "- \"Which conditions frequently co-occur in the same patient?\"\n",
        "\n",
        "These queries will be answered using Pandas and visualized with Matplotlib/Seaborn."
      ],
      "id": "2ReAgbkSvnyN"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9z4F06ovnyN"
      },
      "source": [
        "### Visualizing Data\n",
        "\n",
        "Let's visualize a sample image and its corresponding labels to understand the data better."
      ],
      "id": "f9z4F06ovnyN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMQRgOM2vnyO"
      },
      "outputs": [],
      "source": [
        "# Visualize a sample image\n",
        "data_idx = 42\n",
        "plt.figure()\n",
        "plt.imshow(ds['train_images'][data_idx], cmap='gray')\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.title('Sample Chest X-ray Image')\n",
        "plt.show()\n",
        "\n",
        "# Display corresponding labels\n",
        "labels = ds['train_labels'][data_idx]\n",
        "condition_names = ['Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', 'Nodule',\n",
        "                   'Pneumonia', 'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema',\n",
        "                   'Fibrosis', 'Pleural Thickening', 'Hernia']\n",
        "print('Labels for sample image:')\n",
        "for i, (label, name) in enumerate(zip(labels, condition_names)):\n",
        "    if label == 1:\n",
        "        print(f'- {name}')"
      ],
      "id": "iMQRgOM2vnyO"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMD-4sUWvnyO"
      },
      "source": [
        "## Chain-of-Thought Reasoning and Verification\n",
        "\n",
        "We will answer three natural-language queries using Chain-of-Thought (CoT) reasoning, followed by verification using Pandas. Each query includes a reasoning explanation and cross-checking code."
      ],
      "id": "oMD-4sUWvnyO"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWpE98FNvnyO"
      },
      "source": [
        "### Query 1: Distribution of Labels\n",
        "\n",
        "**Query**: \"How are the labels distributed across the training set?\"\n",
        "\n",
        "**CoT Reasoning**:\n",
        "1. The training labels are stored in `ds['train_labels']`, a NumPy array of shape (num_samples, 14), where each column represents one of the 14 conditions.\n",
        "2. To find the distribution, we need to count how many times each condition is present (value = 1) across all samples.\n",
        "3. We can sum the labels along the sample axis to get the total occurrences of each condition.\n",
        "4. To make the results interpretable, we'll map the counts to condition names and visualize them using a bar plot.\n",
        "5. For verification, we'll load the accompanying CSV file (`dataset.csv`) and compare the label counts.\n",
        "\n",
        "**Code**:\n"
      ],
      "id": "CWpE98FNvnyO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bnxn9d-_vnyO"
      },
      "outputs": [],
      "source": [
        "# Calculate label distribution\n",
        "label_counts = np.sum(ds['train_labels'], axis=0)\n",
        "df_counts = pd.DataFrame({'Condition': condition_names, 'Count': label_counts})\n",
        "\n",
        "# Visualize\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x='Condition', y='Count', data=df_counts)\n",
        "plt.xticks(rotation=45)\n",
        "plt.title('Distribution of Conditions in Training Set')\n",
        "plt.show()\n",
        "\n",
        "# Print counts\n",
        "print('Label counts in training set:')\n",
        "for condition, count in zip(condition_names, label_counts):\n",
        "    print(f'{condition}: {count}')"
      ],
      "id": "Bnxn9d-_vnyO"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf-II41evnyO"
      },
      "source": [
        "**Verification**:\n",
        "To verify, we load the `dataset.csv` file and compute the sum of each condition column for the training split."
      ],
      "id": "bf-II41evnyO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmI9IIB1vnyO"
      },
      "outputs": [],
      "source": [
        "# Load CSV and verify\n",
        "df_csv = pd.read_csv('./Data/ChestMNIST/dataset.csv')\n",
        "train_df = df_csv[df_csv['split'] == 'train']\n",
        "csv_counts = train_df[condition_names].sum()\n",
        "\n",
        "# Compare\n",
        "print('Verification - CSV counts:')\n",
        "for condition, count in csv_counts.items():\n",
        "    print(f'{condition}: {count}')\n",
        "print('\\nMatch:', np.allclose(label_counts, csv_counts.values))"
      ],
      "id": "wmI9IIB1vnyO"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmhazSuhvnyO"
      },
      "source": [
        "**Conclusion**: The bar plot and counts show the distribution of conditions, with some (e.g., Effusion) being more common than others (e.g., Hernia). The CSV verification confirms the counts match, ensuring accuracy."
      ],
      "id": "LmhazSuhvnyO"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gu6RzMX8vnyO"
      },
      "source": [
        "### Query 2: Healthy vs. Diseased Samples\n",
        "\n",
        "**Query**: \"What percentage of samples in the training set are healthy (no conditions)?\"\n",
        "\n",
        "**CoT Reasoning**:\n",
        "1. A sample is healthy if all 14 labels are 0, i.e., the sum of the label vector is 0.\n",
        "2. We can compute the sum of labels for each sample and count how many have a sum of 0.\n",
        "3. The percentage is the number of healthy samples divided by the total number of samples, multiplied by 100.\n",
        "4. For verification, we'll check the CSV file to ensure the count of healthy samples matches.\n",
        "\n",
        "**Code**:\n"
      ],
      "id": "Gu6RzMX8vnyO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--Pv-TNNvnyO"
      },
      "outputs": [],
      "source": [
        "# Calculate healthy samples\n",
        "label_sums = np.sum(ds['train_labels'], axis=1)\n",
        "healthy_count = np.sum(label_sums == 0)\n",
        "total_samples = len(ds['train_labels'])\n",
        "healthy_percentage = (healthy_count / total_samples) * 100\n",
        "\n",
        "print(f'Healthy samples: {healthy_count}')\n",
        "print(f'Total samples: {total_samples}')\n",
        "print(f'Percentage of healthy samples: {healthy_percentage:.2f}%')\n",
        "\n",
        "# Visualize\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.barplot(x=['Healthy', 'Diseased'], y=[healthy_count, total_samples - healthy_count])\n",
        "plt.title('Healthy vs. Diseased Samples in Training Set')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "id": "--Pv-TNNvnyO"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76ayilgbvnyO"
      },
      "source": [
        "**Verification**:\n",
        "We verify by checking the CSV file for rows in the training split where all condition columns are 0."
      ],
      "id": "76ayilgbvnyO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cM_eLsQivnyO"
      },
      "outputs": [],
      "source": [
        "# Verify with CSV\n",
        "healthy_csv = train_df[train_df[condition_names].sum(axis=1) == 0]\n",
        "healthy_csv_count = len(healthy_csv)\n",
        "print(f'Healthy samples (CSV): {healthy_csv_count}')\n",
        "print('Match:', healthy_count == healthy_csv_count)"
      ],
      "id": "cM_eLsQivnyO"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-hIf5TqvnyO"
      },
      "source": [
        "**Conclusion**: The percentage of healthy samples is calculated and visualized, showing the balance between healthy and diseased cases. The CSV verification confirms the count is correct."
      ],
      "id": "d-hIf5TqvnyO"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-m3sXUTvnyO"
      },
      "source": [
        "### Query 3: Most Common Co-occurring Conditions\n",
        "\n",
        "**Query**: \"Which conditions frequently co-occur in the same patient in the training set?\"\n",
        "\n",
        "**CoT Reasoning**:\n",
        "1. Co-occurring conditions are pairs of conditions that are both 1 in the same sample.\n",
        "2. We can compute a correlation matrix of the label columns to identify pairs with high co-occurrence.\n",
        "3. Alternatively, we can count the number of samples where each pair of conditions is present.\n",
        "4. We'll visualize the correlations using a heatmap and list the top pairs.\n",
        "5. For verification, we'll manually count co-occurrences for a few pairs using Pandas.\n",
        "\n",
        "**Code**:\n"
      ],
      "id": "3-m3sXUTvnyO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aurOtoRnvnyP"
      },
      "outputs": [],
      "source": [
        "# Compute correlation matrix\n",
        "label_df = pd.DataFrame(ds['train_labels'], columns=condition_names)\n",
        "corr_matrix = label_df.corr()\n",
        "\n",
        "# Visualize\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.title('Correlation of Conditions in Training Set')\n",
        "plt.show()\n",
        "\n",
        "# Find top co-occurring pairs\n",
        "corr_pairs = corr_matrix.unstack().sort_values(ascending=False)\n",
        "corr_pairs = corr_pairs[corr_pairs < 1]  # Exclude self-correlations\n",
        "print('Top 5 co-occurring condition pairs:')\n",
        "for (cond1, cond2), corr in corr_pairs.head(5).items():\n",
        "    print(f'{cond1} & {cond2}: Correlation = {corr:.3f}')"
      ],
      "id": "aurOtoRnvnyP"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvzMN2QbvnyP"
      },
      "source": [
        "**Verification**:\n",
        "We manually count co-occurrences for the top pair using Pandas."
      ],
      "id": "qvzMN2QbvnyP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADMwy9y-vnyP"
      },
      "outputs": [],
      "source": [
        "# Verify top pair (e.g., Effusion & Edema)\n",
        "top_pair = corr_pairs.index[0]  # First pair\n",
        "cond1, cond2 = top_pair\n",
        "cooccur_count = len(label_df[(label_df[cond1] == 1) & (label_df[cond2] == 1)])\n",
        "total_samples = len(label_df)\n",
        "print(f'Co-occurrences of {cond1} & {cond2}: {cooccur_count}')\n",
        "print(f'Percentage: {(cooccur_count / total_samples) * 100:.2f}%')"
      ],
      "id": "ADMwy9y-vnyP"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GyPL4KRvnyP"
      },
      "source": [
        "**Conclusion**: The heatmap and correlation values identify frequently co-occurring conditions. Manual counting verifies the top pair, ensuring the correlation analysis is accurate."
      ],
      "id": "8GyPL4KRvnyP"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-O_xcE7vnyP"
      },
      "source": [
        "## Exercises: Double-Checking with Pandas\n",
        "\n",
        "These exercises encourage you to verify the results using simple Pandas commands, reinforcing the findings from the queries."
      ],
      "id": "X-O_xcE7vnyP"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEl69k-OvnyP"
      },
      "source": [
        "### Exercise 1: Verify Label Distribution\n",
        "\n",
        "**Task**: Use Pandas to compute the number of occurrences of 'Pneumonia' in the training set and compare it with the result from Query 1.\n",
        "\n",
        "**Code** (fill in the blanks):\n"
      ],
      "id": "KEl69k-OvnyP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7hmBn2QvnyP"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "pneumonia_count = train_df['Pneumonia'].sum()\n",
        "print(f'Pneumonia occurrences: {pneumonia_count}')\n",
        "\n",
        "# Compare with Query 1 result\n",
        "query1_pneumonia = label_counts[condition_names.index('Pneumonia')]\n",
        "print(f'Match with Query 1: {pneumonia_count == query1_pneumonia}')"
      ],
      "id": "O7hmBn2QvnyP"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lwL9w4avnyP"
      },
      "source": [
        "**Solution**:\n",
        "The code above sums the 'Pneumonia' column in the training split of the CSV and compares it with the count from Query 1. The result should match, confirming the label distribution."
      ],
      "id": "4lwL9w4avnyP"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swgWoXeOvnyP"
      },
      "source": [
        "### Exercise 2: Verify Healthy Samples\n",
        "\n",
        "**Task**: Use Pandas to count the number of healthy samples in the validation set and compare with the method used in Query 2.\n",
        "\n",
        "**Code** (fill in the blanks):\n"
      ],
      "id": "swgWoXeOvnyP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Gl1sFNRvnyP"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "val_df = df_csv[df_csv['split'] == 'val']\n",
        "healthy_val = len(val_df[val_df[condition_names].sum(axis=1) == 0])\n",
        "print(f'Healthy samples in validation set: {healthy_val}')\n",
        "\n",
        "# Compare with NumPy method\n",
        "val_label_sums = np.sum(ds['val_labels'], axis=1)\n",
        "healthy_val_numpy = np.sum(val_label_sums == 0)\n",
        "print(f'Match with NumPy: {healthy_val == healthy_val_numpy}')"
      ],
      "id": "5Gl1sFNRvnyP"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tl6PlOWvnyQ"
      },
      "source": [
        "**Solution**:\n",
        "The code filters the validation split and counts rows with no conditions. It compares with the NumPy method from Query 2, ensuring consistency."
      ],
      "id": "-tl6PlOWvnyQ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sCJJAl4vnyQ"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "This notebook demonstrated how to perform natural-language queries on the ChestMNIST dataset using Pandas, with a focus on data exploration, Chain-of-Thought reasoning, and verification. We answered queries about label distribution, healthy samples, and co-occurring conditions, using visualizations and cross-checking with CSV data. The exercises reinforced these findings with simple Pandas commands.\n",
        "\n",
        "### References\n",
        "- ChestMNIST Dataset: https://www.nih.gov/news-events/news-releases/nih-clinical-center-provides-one-largest-publicly-available-chest-x-ray-datasets-scientific-community\n",
        "- Pandas Documentation: https://pandas.pydata.org/docs/\n",
        "- Seaborn Documentation: https://seaborn.pydata.org/"
      ],
      "id": "4sCJJAl4vnyQ"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}