{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFWIESPqzFMI"
      },
      "source": [
        "# Dataset Ingestion and Cleaning (Chest X-ray Dataset)\n",
        "\n",
        "This notebook focuses on ingesting, cleaning, analyzing, and filtering the ChestMNIST dataset. It includes data loading, cleaning, basic statistics, visualizations, and interactive filtering using natural-language prompts. Exercises refine statistical prompts and apply statistical tests.\n",
        "\n",
        "**Author**: Mohammad Rezapourian\n",
        "<br>\n",
        "**Date**: May 12, 2025\n",
        "<br>\n",
        "**License**: Apache-2.0\n",
        "\n",
        "## Table of Contents\n",
        "1. [Initial Setup](#initial-setup)\n",
        "2. [Data Loading and Cleaning](#data-loading-and-cleaning)\n",
        "3. [Basic Statistics](#basic-statistics)\n",
        "4. [Interactive Filtering](#interactive-filtering)\n",
        "5. [Conclusion](#conclusion)"
      ],
      "id": "dFWIESPqzFMI"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2i9M4dtzFMK"
      },
      "source": [
        "## Initial Setup\n",
        "\n",
        "Set up the environment for Google Colab. If running locally, skip to the offline setup."
      ],
      "id": "y2i9M4dtzFMK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0uP9o7EzFMK"
      },
      "outputs": [],
      "source": [
        "# Colab setup\n",
        "!wget -q -O - https://github.com/University-Clinic-of-Neuroradiology/python-bootcamp/archive/refs/heads/main.tar.gz | tar -xzf - --strip-components=2 python-bootcamp-main/notebooks/DeepLearning\n",
        "import os\n",
        "import sys\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "sys.path.insert(0, 'DeepLearning')\n",
        "os.chdir(sys.path[0])\n",
        "%pip install -q numpy matplotlib seaborn pandas scipy\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import scipy.stats as stats"
      ],
      "id": "n0uP9o7EzFMK"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6M0nT-j_zFML"
      },
      "source": [
        "**Note**: If running locally, install dependencies (`pip install numpy matplotlib seaborn pandas scipy`) and use `%matplotlib inline` or `notebook`."
      ],
      "id": "6M0nT-j_zFML"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qghWkxLozFML"
      },
      "source": [
        "## Data Loading and Cleaning\n",
        "\n",
        "Load the ChestMNIST dataset and perform cleaning to ensure data quality."
      ],
      "id": "qghWkxLozFML"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5wLgA9uzFML"
      },
      "outputs": [],
      "source": [
        "# Define paths\n",
        "data_path = './Data/ChestMNIST/chestmnist.npz'\n",
        "csv_path = './Data/ChestMNIST/dataset.csv'\n",
        "\n",
        "# Load NumPy dataset\n",
        "try:\n",
        "    ds = np.load(data_path)\n",
        "    print('Dataset keys:', list(ds.keys()))\n",
        "except FileNotFoundError:\n",
        "    print('Error: chestmnist.npz not found. Ensure the dataset is in ./Data/ChestMNIST/')\n",
        "    raise\n",
        "\n",
        "# Load CSV\n",
        "try:\n",
        "    df = pd.read_csv(csv_path)\n",
        "    print('CSV columns:', df.columns.tolist())\n",
        "except FileNotFoundError:\n",
        "    print('Error: dataset.csv not found. Ensure the CSV is in ./Data/ChestMNIST/')\n",
        "    raise\n",
        "\n",
        "# Display sizes\n",
        "print(f'Training images: {len(ds[\"train_images\"])}')\n",
        "print(f'Validation images: {len(ds[\"val_images\"])}')\n",
        "print(f'Testing images: {len(ds[\"test_images\"])}')\n",
        "print(f'CSV rows: {len(df)}')"
      ],
      "id": "D5wLgA9uzFML"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdLj0ygnzFMM"
      },
      "outputs": [],
      "source": [
        "# Cleaning\n",
        "condition_columns = ['Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', 'Nodule',\n",
        "                    'Pneumonia', 'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema',\n",
        "                    'Fibrosis', 'Pleural Thickening', 'Hernia']\n",
        "print('Missing values:')\n",
        "print(df.isnull().sum())\n",
        "print('Duplicates:', df.duplicated().sum())\n",
        "invalid_labels = df[condition_columns].apply(lambda x: ~x.isin([0, 1])).sum()\n",
        "print('Invalid labels:')\n",
        "print(invalid_labels)\n",
        "invalid_pixels = (ds['train_images'] < 0) | (ds['train_images'] > 255)\n",
        "print('Invalid pixels in train images:', np.any(invalid_pixels))"
      ],
      "id": "GdLj0ygnzFMM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IshqlWPmzFMM"
      },
      "source": [
        "## Basic Statistics\n",
        "\n",
        "Compute summary statistics and visualize condition prevalence."
      ],
      "id": "IshqlWPmzFMM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Axh_6Bd0zFMM"
      },
      "outputs": [],
      "source": [
        "# Summary statistics\n",
        "print('Summary statistics:')\n",
        "print(df[condition_columns].describe())\n",
        "print('Samples per split:')\n",
        "print(df['split'].value_counts())\n",
        "\n",
        "# Prevalence\n",
        "prevalence = df[condition_columns].mean() * 100\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.barplot(x=condition_columns, y=prevalence)\n",
        "plt.xticks(rotation=45)\n",
        "plt.title('Condition Prevalence (%)')\n",
        "plt.ylabel('Prevalence (%)')\n",
        "plt.show()\n",
        "\n",
        "# Number of conditions per sample\n",
        "df['num_conditions'] = df[condition_columns].sum(axis=1)\n",
        "condition_counts = df['num_conditions'].value_counts().sort_index()\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(x=condition_counts.index, y=condition_counts.values)\n",
        "plt.title('Number of Conditions per Sample')\n",
        "plt.xlabel('Number of Conditions')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "id": "Axh_6Bd0zFMM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POTEzJcIzFMM"
      },
      "source": [
        "**Exercise**: Refine the prompt to show percentages instead of counts for the number of conditions.\n",
        "\n",
        "**Prompt**: \"Show the percentage of samples for each number of conditions.\"\n"
      ],
      "id": "POTEzJcIzFMM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdpjzIJpzFMM"
      },
      "outputs": [],
      "source": [
        "# Exercise solution\n",
        "total_samples = len(df)\n",
        "condition_percentages = (condition_counts / total_samples) * 100\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(x=condition_percentages.index, y=condition_percentages.values)\n",
        "plt.title('Percentage of Samples by Number of Conditions')\n",
        "plt.xlabel('Number of Conditions')\n",
        "plt.ylabel('Percentage (%)')\n",
        "plt.show()\n",
        "print('Percentages:')\n",
        "for num, perc in condition_percentages.items():\n",
        "    print(f'{num} conditions: {perc:.2f}%')"
      ],
      "id": "HdpjzIJpzFMM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwSHIyH6zFMM"
      },
      "source": [
        "## Interactive Filtering\n",
        "\n",
        "Filter the dataset using natural-language prompts."
      ],
      "id": "cwSHIyH6zFMM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Szu9Hq8ezFMM"
      },
      "outputs": [],
      "source": [
        "def filter_data(prompt, df):\n",
        "    if 'Pneumonia' in prompt:\n",
        "        filtered = df[df['Pneumonia'] == 1]\n",
        "        print(f'Filtered {len(filtered)} samples with Pneumonia.')\n",
        "    elif 'Effusion and Edema' in prompt:\n",
        "        filtered = df[(df['Effusion'] == 1) & (df['Edema'] == 1)]\n",
        "        print(f'Filtered {len(filtered)} samples with Effusion and Edema.')\n",
        "    elif 'healthy' in prompt:\n",
        "        filtered = df[df[condition_columns].sum(axis=1) == 0]\n",
        "        print(f'Filtered {len(filtered)} healthy samples.')\n",
        "    else:\n",
        "        filtered = df\n",
        "        print('No filter applied.')\n",
        "    return filtered\n",
        "\n",
        "prompts = ['Show samples with Pneumonia.', 'Filter samples with both Effusion and Edema.', 'Get healthy samples.']\n",
        "for prompt in prompts:\n",
        "    print(f'Prompt: {prompt}')\n",
        "    filtered_df = filter_data(prompt, df)\n",
        "    print('Prevalence (%):')\n",
        "    print(filtered_df[condition_columns].mean() * 100)"
      ],
      "id": "Szu9Hq8ezFMM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_U6lqyQwzFMM"
      },
      "source": [
        "**Exercise**: Filter samples with at least three conditions and test Effusion prevalence.\n",
        "\n",
        "**Prompt**: \"Filter samples with at least three conditions.\"\n"
      ],
      "id": "_U6lqyQwzFMM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2aBQ6TtzFMN"
      },
      "outputs": [],
      "source": [
        "# Exercise solution\n",
        "filtered_df = df[df['num_conditions'] >= 3]\n",
        "print(f'Filtered {len(filtered_df)} samples.')\n",
        "effusion_all = df['Effusion'].mean()\n",
        "effusion_filtered = filtered_df['Effusion'].mean()\n",
        "print(f'Effusion prevalence (all): {effusion_all * 100:.2f}%')\n",
        "print(f'Effusion prevalence (filtered): {effusion_filtered * 100:.2f}%')\n",
        "count_all = df['Effusion'].sum()\n",
        "n_all = len(df)\n",
        "count_filtered = filtered_df['Effusion'].sum()\n",
        "n_filtered = len(filtered_df)\n",
        "z_stat, p_value = stats.proportions_ztest([count_filtered, count_all], [n_filtered, n_all])\n",
        "print(f'Z-statistic: {z_stat:.2f}, P-value: {p_value:.4f}')"
      ],
      "id": "v2aBQ6TtzFMN"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m23FHnO2zFMN"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "This notebook ingested, cleaned, and analyzed the ChestMNIST dataset, with interactive filtering and statistical tests.\n",
        "\n",
        "**References**:\n",
        "- https://www.nih.gov/news-events/news-releases/nih-clinical-center-provides-one-largest-publicly-available-chest-x-ray-datasets-scientific-community\n",
        "- https://pandas.pydata.org/docs/\n",
        "- https://seaborn.pydata.org/"
      ],
      "id": "m23FHnO2zFMN"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}