{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Pandas\n",
    "You'll learn the basic concepts of Pandas.\n",
    "\n",
    "This demo is a jupyter notebook, i.e. intended to be run step by step.\n",
    "\n",
    "Author: Eric Einspänner\n",
    "<br>\n",
    "Contributor: Nastaran Takmilhomayouni\n",
    "\n",
    "First version: 6th of July 2023\n",
    "\n",
    "\n",
    "Copyright 2023 Clinic of Neuroradiology, Magdeburg, Germany\n",
    "\n",
    "License: Apache-2.0\n",
    "\n",
    "*All data used here are fictitious.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "0. [Initial Set-Up for Google Colab](#initial-set-up-for-google-colab)\n",
    "1. [Initial Set-Up (offline)](#initial-set-up-offline)\n",
    "2. [Creating DataFrames from scratch](#creating-dataframes-from-scratch)\n",
    "3. [Viewing your data](#viewing-your-data)\n",
    "4. [Getting some informations about your data](#getting-some-informations-about-your-data)\n",
    "5. [Handling duplicates](#handling-duplicates)\n",
    "6. [Column cleanup](#column-cleanup)\n",
    "7. [Manage missing values](#manage-missing-values)\n",
    "   1. [Imputation](#imputation)\n",
    "8. [Removing null values](#removing-null-values)\n",
    "9.  [Understanding your variables](#understanding-your-variables)\n",
    "10. [DataFrame slicing, selecting, extracting](#dataframe-slicing-selecting-extracting)\n",
    "    1.  [By column](#by-column)\n",
    "    2.  [By rows](#by-rows)\n",
    "    3.  [Conditional selections](#conditional-selections)\n",
    "11. [Plotting](#plotting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Set-Up for Google Colab\n",
    "<u> Execute these code blocks just in Google Colab! </u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/University-Clinic-of-Neuroradiology/python-bootcamp.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from google.colab import output\n",
    "output.enable_custom_widget_manager()\n",
    "\n",
    "sys.path.insert(0,'/content/python-bootcamp/notebooks/DataManagement')\n",
    "os.chdir(sys.path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q ipympl numpy matplotlib pandas seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Set-Up (offline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports etc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --- Start notebook ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating DataFrames from scratch\n",
    "There are many ways to create a DataFrame from scratch, but a great option is to just use a simple `dict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'sex': ['M', 'W', 'W', 'M'], \n",
    "    'age': [66, 56, 71, 62]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then pass it to the pandas DataFrame constructor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = pd.DataFrame(data)\n",
    "print(patients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each `(key, value)` item in data corresponds to a column in the resulting DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Index of this DataFrame was given to us on creation as the numbers 0-3, but we could also create our own when we initialize the DataFrame.\n",
    "\n",
    "Let's have patient IDs as our index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = pd.DataFrame(data, index=['56171', '34167', '89143', '56124'])\n",
    "print(patients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attention:** We do not want to use integers as patient IDs, but strings!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we could locate a patient by using their ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(patients.loc['34167'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random patient IDs\n",
    "patient_ids = ['54793', '39267', '69143', '12894', '64823', '38167', '89144', '56125', '34591', '44167']\n",
    "\n",
    "# Generate random sex data\n",
    "sex_data = np.random.choice(['M', 'W'], size=10)\n",
    "\n",
    "# Generate random age data\n",
    "age_data = np.random.randint(50, 81, size=10)\n",
    "\n",
    "# Generate random aneurysm data\n",
    "aneurysm_data = np.random.choice(['y', 'n'], size=10)\n",
    "\n",
    "# Generate random aneurysm size data (when aneurysm is present)\n",
    "aneurysm_size_data = [np.random.randint(5, 15) if aneurysm == 'y' else np.nan for aneurysm in aneurysm_data]\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'patient_id': patient_ids,\n",
    "    'Sex': sex_data,\n",
    "    'age': age_data,\n",
    "    'aneurysm': aneurysm_data,\n",
    "    'Aneurysm Size [mm]': aneurysm_size_data\n",
    "})\n",
    "\n",
    "# Set Patient ID as index\n",
    "df.set_index('patient_id', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to do when opening a new dataset is print out a few rows to keep as a visual reference. `.head()` outputs the first five rows of your DataFrame by default, but we could also pass a number as well: `df.head(7)` would output the top seven rows, for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the last five rows use `.tail()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting some informations about your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `.info()` you get a bunch of informations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.info()` provides the essential details about your dataset, such as the number of rows and columns, the number of non-null values, what type of data is in each column, and how much memory your DataFrame is using."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notice:** in our dataset we have some obvious missing values in the `aneurysm_size_mm` column. We'll look at how to handle those in a bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another fast and useful attribute is `.shape` (like for np.arrays), which outputs just a tuple of (rows, columns):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset does not have duplicate rows, but it is always important to verify you aren't aggregating duplicate rows.\n",
    "\n",
    "To demonstrate, let's simply just double up our DataFrame by appending it to itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.concat([df, df])\n",
    "\n",
    "print(temp_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** We are capturing this copy in `temp` so we aren't working with the real data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can try dropping duplicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = temp_df.drop_duplicates()\n",
    "\n",
    "print(temp_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many times datasets will have verbose column names with symbols, upper and lowercase words, spaces, and typos. To make selecting data by column name easier we can spend a little time cleaning up their names.\n",
    "\n",
    "Here's how to print the column names of our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `.rename()` method to rename certain or all columns via a dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\n",
    "    'Sex': 'sex',\n",
    "    'Aneurysm Size [mm]': 'aneurysm_size_mm'\n",
    "    }, inplace=True)\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manage missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When exploring data, you’ll most likely encounter missing or null values, which are essentially placeholders for non-existent values. Most commonly you'll see Python's `None` or NumPy's `np.nan`, each of which are handled differently in some situations.\n",
    "\n",
    "There are two options in dealing with nulls:\n",
    "- Get rid of rows or columns with nulls\n",
    "- Replace nulls with non-null values, a technique known as **imputation**\n",
    "\n",
    "Let's calculate to total number of nulls in each column of our dataset. The first step is to check which cells in our DataFrame are null:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice `isnull()` returns a DataFrame where each cell is either True or False depending on that cell's null status.\n",
    "\n",
    "To count the number of nulls in each column we use an aggregate function for summing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove nulls is pretty simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = df.dropna()\n",
    "\n",
    "print(temp_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This operation will delete any row with at least a single null value, but it will return a new DataFrame without altering the original one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputation is a conventional feature engineering technique used to keep valuable data that have null values.\n",
    "\n",
    "There may be instances where dropping every row with a null value removes too big a chunk from your dataset, so instead we can impute that null with another value, usually the mean or the median of that column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Of course it doesn't make any sense here, but we would like to show you briefly how it works!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at imputing the missing values in the `aneurysm_size_mm` column. First we'll extract that column into its own variable. Using square brackets is the general way we select columns in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aneurysm_size = df['aneurysm_size_mm']\n",
    "\n",
    "print(aneurysm_size.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll impute the missing values of `aneurysm_size_mm` using the mean. Here's the mean value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aneurysm_size_mean = aneurysm_size.mean()\n",
    "\n",
    "print(aneurysm_size_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the mean, let's fill the nulls using fillna():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = df.fillna(aneurysm_size_mean)\n",
    "\n",
    "print(temp_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imputing an entire column with the same value like this is a basic example. It would be a better idea to try a more granular imputation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding your variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `describe()` on an entire DataFrame we can get a summary of the distribution of continuous variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.describe()` can also be used on a single column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['sex'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.value_counts()` can tell us the frequency of all values in a column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['aneurysm'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame slicing, selecting, extracting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important function is the targeted selection of data from the DataFrame.\n",
    "\n",
    "It's important to note that, although many methods are the same, DataFrames and Series have different attributes, so you'll need be sure to know which type you are working with or else you will receive attribute errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By column\n",
    "You can extract a column using square brackets like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_col = df['age']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, check the type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(age_col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will return a Series. To extract a column as a DataFrame, you need to pass a list of column names. In our case that's just a single column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_col = df[['age']]\n",
    "\n",
    "print(type(age_col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it's just a list, adding another column name is easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = df[['age', 'aneurysm']]\n",
    "\n",
    "print(temp_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By rows\n",
    "For rows, we have two options:\n",
    "- `.loc` - locates by name\n",
    "- `.iloc`- locates by numerical index\n",
    "Remember that we are still indexed by patient ID, so to use `.loc` we give it the `patient_id`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_39267 = df.loc['39267']\n",
    "\n",
    "print(pat_39267)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, with `iloc` we give it the numerical index of the patient ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_39267 = df.iloc[1]\n",
    "\n",
    "print(pat_39267)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`loc` and `iloc` can be thought of as similar to Python list slicing. To show this even further, let's select multiple rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_subset = df.loc[['39267', '12894']]\n",
    "\n",
    "print(pat_subset)\n",
    "\n",
    "pat_subset = df.iloc[[1, 3]]\n",
    "\n",
    "print(pat_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conditional selections\n",
    "We’ve gone over how to select columns and rows, but what if we want to make a conditional selection?\n",
    "\n",
    "To do that, we take a column from the DataFrame and apply a Boolean condition to it. Here's an example of a Boolean condition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = (df['age'] > 60)\n",
    "\n",
    "print(condition.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to `isnull()`, this returns a Series of True and False values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to filter out all patients that are older than 60, in other words, we don’t want the False ages. To return the rows where that condition is True we have to pass this operation into the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = df[df['age'] > 60]\n",
    "\n",
    "print(temp_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make some richer conditionals by using logical operators `|` for \"or\" and `&` for \"and\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = df[(df['age'] > 60) & (df['aneurysm'] == 'y')]\n",
    "\n",
    "print(temp_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to make sure to group evaluations with parentheses so Python knows how to evaluate the conditional.\n",
    "\n",
    "Using the `isin()` method we could make this more concise though:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = df[df['aneurysm'].isin(['y'])]\n",
    "\n",
    "print(temp_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting\n",
    "Another great thing about pandas is that it integrates with Matplotlib, so you get the ability to plot directly off DataFrames and Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind='scatter', x='age', y='aneurysm_size_mm', title='Aneurysm Size by Age', color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By combining categorical and continuous data, we can create a Boxplot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.boxplot(column='aneurysm_size_mm', by='aneurysm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to plot a simple Histogram based on a single column, we can call plot on a column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['aneurysm']=='y')].plot(kind='hist', y='age', title='Age distribution by positive aneurysm', color='g', bins=5, alpha=0.5, legend=False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
