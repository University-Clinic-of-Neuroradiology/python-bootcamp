{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building deep learning models for classification\n",
    "You'll use the Keras library to build deep learning models for classification. By the end of the chapter, you'll have all the tools necessary to build deep neural networks.\n",
    "\n",
    "This demo is a jupyter notebook, i.e. intended to be run step by step.\n",
    "\n",
    "Author: Eric Einspänner\n",
    "\n",
    "First version: 6th of July 2023\n",
    "\n",
    "\n",
    "Copyright 2023 Clinic of Neuroradiology, Magdeburg, Germany\n",
    "\n",
    "License: Apache-2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table Of Contents\n",
    "1. [Intial set-up](#initial-set-up)\n",
    "2. [Load Data](#load-data)\n",
    "    - [Details](#details)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure figures appears inline and animations works\n",
    "# Edit this to \"\"%matplotlib notebook\" when using the \"classic\" jupyter notebook interface\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speaking of graphics, we're going to tackle a challenge that seemed almost impossible decades ago: image classification with computer vision. Specifically, we will try to classify ... from the Chest MedMNIST dataset. A few samples are shown below. The ChestMNIST is based on the NIH-ChestXray14 dataset [1], a dataset comprising 112,120 frontal-view X-Ray images of 30,805 unique patients with the text-mined 14 disease labels, which could be formulized as a multi-label binary-class classification task. We use the official data split, and resize the source images of 1 × 1,024 × 1,024 into 1 × 28 × 28. \n",
    "\n",
    "![alt text](Images/ChestMNIST.jpg \"Chest MNIST\")\n",
    "\n",
    "Neural networks attempt to copy the human learning technique, Trial and Error. To do this, we will create something like a set of digital flashcards. Our artificial brains will attempt to guess what kind of clothing we are showing it with a flashcard, then we will give it the answer, helping the computer learn from its successes and mistakes.\n",
    "\n",
    "Just like how students are quizzed to test their understanding, we will set aside a portion of our data to quiz our neural networks to make sure they understand the concepts we're trying to teach them, as opposed to them memorizing the answers to their study questions. For trivia, memorization might be an acceptable strategy, but for skills, like adding two numbers, memorization won't get our models very far.\n",
    "\n",
    "The study data is often called the `training dataset` and the quiz data is often called the `validation dataset`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Math\n",
    "\n",
    "Computers are built with discrete 0s and 1s whereas humans and animals are built on more continuous building blocks. Because of this, some of the first neurons attempted to mimic biological neurons with a linear regression function: `y = mx + b`. The `x` is like information coming in through the dendrites and the `y` is like the output through the terminals. As the computer guesses more and more answers to the questions we present it, it will update its variables (`m` and `b`) to better fit the line to the data it has seen.\n",
    "\n",
    "Neurons are often exposed to multivariate data. We're going to build a neuron that takes each pixel value (which is between `0` and `255`), and assign it a weight, which is equivalent to our `m`. Data scientists often express this weight as `w`. For example, the first pixel will have a weight of `w0`, the second will have a weight of `w1`, and so on. Our full equation becomes `y = w0x0 + w1x1 + w2x2 + ... + b`.\n",
    "\n",
    "Each image is 28 pixels by 28 pixels, so we will have a total of 784 weights. A pixel value of `0` would be black and a pixel value of `255` would be white. Let's look at the raw pixel values of the previous image we plotted. Each number below will be assigned a weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to dataset\n",
    "data_path = './Data/ChestMNIST/chestmnist.npz'\n",
    "\n",
    "# Load the dataset\n",
    "ds = np.load(data_path)\n",
    "print('Content of dataset: ', list(ds.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of train images: {} and number of labels: {}.'.format(len(ds['train_images']), len(ds['train_labels'])))\n",
    "print('Number of validation images: {} and number of labels: {}.'.format(len(ds['val_images']), len(ds['val_labels'])))\n",
    "print('Number of testing images: {} and number of labels: {}.'.format(len(ds['test_images']), len(ds['test_labels'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with our `train_images` and `train_labels`. `train_images` are like the question on our flashcards and `train_labels` are like the answer. In general, data scientists often refer to this answer as the label.\n",
    "\n",
    "We can plot one of these images to see what it looks like. To do so, we will use Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The question number to study with. Feel free to change up to 78468.\n",
    "data_idx = 42\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(ds['train_images'][data_idx], cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What would you classify this as?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['train_labels'][data_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that this is mainly a dataset of 112,120 samples and has the following nature:\n",
    "\n",
    "- Multi-Label: A sample may have multiple different Labels at the same time\n",
    "- Binary Class: Each label is a binary classification\n",
    "\n",
    "These categories are:\n",
    "- 0: atelectasis: Insufficiency of lung inflation\n",
    "- 1: cardiomegaly: hypertrophy of the heart\n",
    "- 2: effusion: exudate\n",
    "- 3: Infiltration: Infiltration\n",
    "- 4: mass: a lump\n",
    "- 5: nodule: nodules\n",
    "- 6: pneumonia: pneumonia\n",
    "- 7: Pneumothorax: pneumothorax\n",
    "- 8: consolidation: (lung) real changes\n",
    "- 9: EDEMA: pulmonary edema\n",
    "- 10: Emphysema: emphysema\n",
    "- 11: fibrosis: fibrosis\n",
    "- 12: pleural thickening: pleural thickening\n",
    "- 13: Hernia: Hernia\n",
    "\n",
    "We would now like to know how the data is divided between the individual cases. Patients without a specific diagnosis are considered healthy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('./Data/ChestMNIST/dataset.csv')\n",
    "\n",
    "# Reshape the DataFrame using melt\n",
    "df_long = df.melt(id_vars=['split', 'img'])\n",
    "\n",
    "# Filter out rows with value = 0\n",
    "df_long = df_long[df_long['value'] != 0]\n",
    "\n",
    "# Create the bar plot using seaborn\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='variable', hue='split', data=df_long)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Your task in this exercise is to plot one sample (e.g. 89) and the correspondig label of the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here (the solution is below)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Solution\n",
    "# The question number to quiz with. Feel free to change up to 11219.\n",
    "data_idx = 89\n",
    "\n",
    "print(ds['val_labels'][data_idx])\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(ds['val_images'][data_idx], cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data summary\n",
    "According to the introduction of our data a few days ago, we can know that ChestMNIST is a dataset with the following characteristics:\n",
    "\n",
    "- Each data point is a chest X-ray image\n",
    "- The resolution of each image is 28x28\n",
    "- Since it is grayscale, the channel of the image is 1 (compared to 3 for common RGB)\n",
    "- The Outcome part predicts whether there are 14 different symptoms (and there may be several) in the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "In the below model, we have two layers:\n",
    "* [Flatten](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten) - Converts multidimensional data into 1 dimensional data (ex: a list of lists into a single list).\n",
    "* [Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) -  A \"row\" of neurons. Each neuron has a weight (`w`) for each input. In the example below, we use the number `10` to place ten neurons.\n",
    "\n",
    "We will also define an `input_shape` which is the dimensions of our data. In this case, our `28x28` pixels for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_classes = len(ds['train_labels'][0])\n",
    "number_of_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(784, input_shape=(28,28), activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(number_of_classes, activation='sigmoid'))\n",
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add layers\n",
    "model.add(Flatten(input_shape=(28, 28)))  # Flatten the input data\n",
    "model.add(Dense(128, activation='relu'))   # Fully connected layer with ReLU activation\n",
    "model.add(Dense(64, activation='relu'))    # Fully connected layer with ReLU activation\n",
    "model.add(Dense(number_of_classes, activation='sigmoid')) # Output layer with sigmoid activation for multi-label classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying the model\n",
    "\n",
    "To make sure our model has the structure we expect, we can call the [summary](https://www.tensorflow.org/js/guide/models_and_layers#model_summary) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_5 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 14)                910       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109646 (428.30 KB)\n",
      "Trainable params: 109646 (428.30 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our total parameter count is ???."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few other ways to verify our model. We can also [plot](https://keras.io/api/utils/model_plotting_utils/) it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate Training\n",
    "\n",
    "We have a model setup, but how does it learn? Just like how students are scored when they take a test, we need to give the model a function to grade its performance. Such a function is called the `loss` function.\n",
    "\n",
    "In this case, we're going to use a type of function specific to classification called [SparseCategoricalCrossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy):\n",
    "* **Sparse** - for this function, it refers to how our label is an integer index for our categories\n",
    "* **Categorical** - this function was made for classification\n",
    "* **Cross-entropy** - the more confident our model is when it makes an incorrect guess, the worse its score will be. If a model is 100% confident when it is wrong, it will have a score of negative infinity!\n",
    "* `from_logits` - the linear output will be transformed into a probability which can be interpreted as the model's confidence that a particular category is the correct one for the given input.\n",
    "\n",
    "This type of loss function works well for our case because it grades each of the neurons simultaneously. If all of our neurons give a strong signal that they're the correct label, we need a way to tell them that they can't all be right.\n",
    "\n",
    "For us humans, we can add additional `metrics` to monitor how well our model is learning. For instance, maybe the loss is low, but what if the `accuracy` is not high?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model\n",
    "\n",
    "Now the moment of truth! The below [fit](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit) method will both help our model study and quiz it.\n",
    "\n",
    "An `epoch` is one review of the training dataset. Just like how school students might need to review a flashcard multiple times before the concept \"clicks\", the same is true of our models.\n",
    "\n",
    "After each `epoch`, the model is quizzed with the validation data. Let's watch it work hard and improve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((78468, 28, 28), (78468, 14))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train_images'].shape, ds['train_labels'].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2433/2453 [============================>.] - ETA: 0s - loss: 0.4454 - accuracy: 0.1619"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\einspaen\\AppData\\Local\\miniconda3\\envs\\bootcamp\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1972, in test_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\einspaen\\AppData\\Local\\miniconda3\\envs\\bootcamp\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1956, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\einspaen\\AppData\\Local\\miniconda3\\envs\\bootcamp\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1944, in run_step  **\n        outputs = model.test_step(data)\n    File \"c:\\Users\\einspaen\\AppData\\Local\\miniconda3\\envs\\bootcamp\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1852, in test_step\n        self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\einspaen\\AppData\\Local\\miniconda3\\envs\\bootcamp\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1139, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\einspaen\\AppData\\Local\\miniconda3\\envs\\bootcamp\\lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\einspaen\\AppData\\Local\\miniconda3\\envs\\bootcamp\\lib\\site-packages\\keras\\src\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\einspaen\\AppData\\Local\\miniconda3\\envs\\bootcamp\\lib\\site-packages\\keras\\src\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\einspaen\\AppData\\Local\\miniconda3\\envs\\bootcamp\\lib\\site-packages\\keras\\src\\losses.py\", line 2432, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"c:\\Users\\einspaen\\AppData\\Local\\miniconda3\\envs\\bootcamp\\lib\\site-packages\\keras\\src\\backend.py\", line 5809, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 14) vs (None, 28, 28)).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      2\u001b[0m     ds[\u001b[39m'\u001b[39;49m\u001b[39mtrain_images\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m      3\u001b[0m     ds[\u001b[39m'\u001b[39;49m\u001b[39mtrain_labels\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m      4\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m,\n\u001b[0;32m      5\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,\n\u001b[0;32m      6\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m      7\u001b[0m     validation_data\u001b[39m=\u001b[39;49m(ds[\u001b[39m'\u001b[39;49m\u001b[39mval_images\u001b[39;49m\u001b[39m'\u001b[39;49m], ds[\u001b[39m'\u001b[39;49m\u001b[39mval_images\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m      8\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\einspaen\\AppData\\Local\\miniconda3\\envs\\bootcamp\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\Temp\\einspaen\\__autograph_generated_filek8ahcixk.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__test_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\einspaen\\AppData\\Local\\miniconda3\\envs\\bootcamp\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1972, in test_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\einspaen\\AppData\\Local\\miniconda3\\envs\\bootcamp\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1956, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\einspaen\\AppData\\Local\\miniconda3\\envs\\bootcamp\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1944, in run_step  **\n        outputs = model.test_step(data)\n    File \"c:\\Users\\einspaen\\AppData\\Local\\miniconda3\\envs\\bootcamp\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1852, in test_step\n        self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\einspaen\\AppData\\Local\\miniconda3\\envs\\bootcamp\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1139, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\einspaen\\AppData\\Local\\miniconda3\\envs\\bootcamp\\lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\einspaen\\AppData\\Local\\miniconda3\\envs\\bootcamp\\lib\\site-packages\\keras\\src\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\einspaen\\AppData\\Local\\miniconda3\\envs\\bootcamp\\lib\\site-packages\\keras\\src\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\einspaen\\AppData\\Local\\miniconda3\\envs\\bootcamp\\lib\\site-packages\\keras\\src\\losses.py\", line 2432, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"c:\\Users\\einspaen\\AppData\\Local\\miniconda3\\envs\\bootcamp\\lib\\site-packages\\keras\\src\\backend.py\", line 5809, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 14) vs (None, 28, 28)).\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    ds['train_images'],\n",
    "    ds['train_labels'],\n",
    "    epochs=5,\n",
    "    batch_size=32,\n",
    "    verbose=True,\n",
    "    validation_data=(ds['val_images'], ds['val_images'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_acc = history.history['accuracy']\n",
    "history_val_acc = history.history['val_accuracy']\n",
    "history_loss = history.history['loss']\n",
    "history_val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acc_loss(history):\n",
    "    plt.figure(figsize=(20, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.legend()\n",
    "\n",
    "plot_acc_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "\n",
    "Time to graduate our model and let it enter the real world. We can use the [predict](https://www.tensorflow.org/api_docs/python/tf/keras/Model#predict) method to see the output of our model on a set of images, regardless of if they were in the original datasets or not.\n",
    "\n",
    "Please note, Keras expects a batch, or multiple datapoints, when making a prediction. To make a prediction on a single point of data, it should be converted to a batch of one datapoint.\n",
    "\n",
    "Below are the predictions for the items in our `test dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(ds['test_images'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are raw results and need some formatting to be interpreted by the average human, so below, we've displayed an image to be classified as well as graph the results of each of our output neurons. The larger the value, the more confident the neuron is that it corresponds to the correct label (and the more negative it is, the more confident it is that it is not the correct label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_idx = 8675 # The question number to study with. Feel free to change up to 22432.\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(ds['test_images'][data_idx], cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n",
    "x_values = range(number_of_classes)\n",
    "plt.figure()\n",
    "plt.bar(x_values, model.predict(ds['test_images'][data_idx:data_idx+1]).flatten())\n",
    "plt.xticks(len(number_of_classes))\n",
    "plt.show()\n",
    "\n",
    "print(\"correct answer:\", ds['test_labels'][data_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Congratulations on completing the notebook! While this model does significantly better than random guessing, it has a way to go before it can beat humans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "<a id=\"1\">[1]</a>\n",
    "Wang, X. et al. (2017)\n",
    "Chestx-ray8: Hospital-scale chest x-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases.\n",
    "In Conference on Computer Vision and Pattern Recognition, 3462–3471"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bootcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
