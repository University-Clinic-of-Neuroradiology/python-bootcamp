{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration of Measurement\n",
    "You'll using a a 4D time series in this notebook. Along the way, you'll learn the fundamentals of image segmentation, object labeling, and morphological measurement. \n",
    "\n",
    "This demo is a jupyter notebook, i.e. intended to be run step by step.\n",
    "\n",
    "Author: Eric Einsp√§nner\n",
    "<br>\n",
    "Contributor: Nastaran Takmilhomayouni\n",
    "\n",
    "First version: 6th of July 2023\n",
    "\n",
    "\n",
    "Copyright 2023 Clinic of Neuroradiology, Magdeburg, Germany\n",
    "\n",
    "License: Apache-2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "0. [Initial Set-Up for Google Colab](#initial-set-up-for-google-colab)\n",
    "1. [Initial Set-Up (offline)](#initial-set-up-offline)\n",
    "2. [Load image/volume](#Load-the-Image/Volume)\n",
    "3. [Segmentation](#Segmentation)\n",
    "    - [Exercise (Segmentation)](#exercise-segmentation)\n",
    "4. [Select objects](#Select-Objects)\n",
    "5. [Extract objects](#Extract-Objects)\n",
    "6. [Measure variance](#Measure-Variance)\n",
    "7. [Separate histograms](#Separate-Histograms)\n",
    "8. [Calculate distances](#Calculate-Distance)\n",
    "9. [COM](#Center-of-Mass-COM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Set-Up for Google Colab\n",
    "<u> Execute these code blocks just in Google Colab! </u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/University-Clinic-of-Neuroradiology/python-bootcamp.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from google.colab import output\n",
    "output.enable_custom_widget_manager()\n",
    "\n",
    "sys.path.insert(0,'/content/python-bootcamp/notebooks/ImageAnalysis')\n",
    "os.chdir(sys.path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q ipympl numpy matplotlib imageio pydicom SciPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import imageio\n",
    "import scipy.ndimage as ndi\n",
    "import pydicom\n",
    "from pydicom.data import get_testdata_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Set-Up (offline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure figures appears inline and animations works\n",
    "# Edit this to \"\"%matplotlib notebook\" when using the \"classic\" jupyter notebook interface\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports etc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import imageio\n",
    "import scipy.ndimage as ndi\n",
    "import pydicom\n",
    "from pydicom.data import get_testdata_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --- Start notebook ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function `format_and_render_plot()` is just a simplify formatting method for the plots in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_and_render_plot(axis=False, legend=False):\n",
    "    '''\n",
    "    Custom function to simplify common formatting operations for exercises. Operations include: \n",
    "    1. Turning off axis grids and legends, if not explicitly requested.\n",
    "    2. Calling `plt.tight_layout` to improve subplot spacing.\n",
    "    3. Calling `plt.show()` to render plot.\n",
    "    '''\n",
    "    fig = plt.gcf()\n",
    "    for ax in fig.axes:\n",
    "        if not axis:\n",
    "            ax.axis('off')\n",
    "        if legend:  \n",
    "            ax.legend(loc='center right')  \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Image/Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the directory (volume)\n",
    "folder_path = 'Data/Brain/SE000001/MR000000'\n",
    "\n",
    "# Load the volume\n",
    "vol = imageio.volread(folder_path)\n",
    "print(vol.shape)\n",
    "\n",
    "# save the middle slice as separat image\n",
    "middle_slice = vol.shape[0] // 2            # // is floor division\n",
    "im = vol[middle_slice,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min-max normalisation\n",
    "im_old = im                                     # save original image for later\n",
    "im = (im - im.min()) / (im.max() - im.min())    # normalise the image, range 0 - 1\n",
    "\n",
    "# Print the image's data type, minimum and maximum intensity\n",
    "print('Data type:', im.dtype)\n",
    "print('Min. value:', im.min())\n",
    "print('Max value:', im.max())\n",
    "\n",
    "# Plot the grayscale images\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "axes[0].imshow(im_old, cmap='gray')\n",
    "axes[0].set_title('without normalization', fontweight =\"bold\")\n",
    "axes[1].imshow(im, cmap='gray')\n",
    "axes[1].set_title('with normalization', fontweight =\"bold\")\n",
    "format_and_render_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation\n",
    "In this chapter, we'll work with magnetic resonance (MR) imaging data. The full image is a 3D time series spanning.\n",
    "\n",
    "We start by smoothing our image so that we get a better result when we subsequently segment it. We use `ndi.binary_closing()` to fill any gaps in our mask. At the end we want to label the features of our mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smooth intensity values\n",
    "im_filt = ndi.median_filter(im, size=3)         # size = 3 means 3x3x3 neighbourhood\n",
    "\n",
    "# Select high-intensity pixels\n",
    "mask_start = np.where(im_filt > 0.3, 1, 0)      # mask_start is a boolean array\n",
    "mask = ndi.binary_closing(mask_start)           # fill holes\n",
    "\n",
    "# Label the objects in \"mask\"\n",
    "labels, nlabels = ndi.label(mask)               # labels: each object has a unique number, nlabels: number of objects\n",
    "print('Num. Labels:', nlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a `labels` overlay\n",
    "overlay = np.where(labels > 0, labels, np.nan)\n",
    "\n",
    "# Use imshow to plot the overlay\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "axes[0].imshow(im, cmap='gray')\n",
    "axes[0].set_title('original', fontweight =\"bold\")\n",
    "axes[1].imshow(im, cmap='gray')                             # show image first\n",
    "axes[1].imshow(overlay, cmap='rainbow', alpha=0.6)          # show overlay second; alpha controls transparency\n",
    "axes[1].set_title('with segmentation', fontweight =\"bold\")\n",
    "format_and_render_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise (Segmentation)\n",
    "Try some other paramters and observe the changes. Use new names for `im_filt`, `mask_start`, `mask`, `overlay` and the `labels`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Solution - just an example, try your own\n",
    "# Smooth intensity values\n",
    "new_im_filt = ndi.median_filter(im, size=4)\n",
    "\n",
    "# Select high-intensity pixels\n",
    "new_mask_start = np.where(new_im_filt > 0.35, 1, 0)\n",
    "new_mask = ndi.binary_closing(new_mask_start, iterations=2)\n",
    "\n",
    "# Label the objects in \"mask\"\n",
    "new_labels, new_nlabels = ndi.label(new_mask)\n",
    "print('Num. Labels:', new_nlabels)\n",
    "\n",
    "# Create a `labels` overlay\n",
    "new_overlay = np.where(new_labels > 0, new_labels, np.nan)\n",
    "\n",
    "# Use imshow to plot the overlay\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "axes[0].imshow(im, cmap='gray')\n",
    "axes[0].set_title('original', fontweight =\"bold\")\n",
    "axes[1].imshow(im, cmap='gray')\n",
    "axes[1].imshow(new_overlay, cmap='rainbow', alpha=0.6)\n",
    "axes[1].set_title('with segmentation', fontweight =\"bold\")\n",
    "format_and_render_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Objects\n",
    "Labels are like object \"handles\" - they give you a way to pick up whole sets of pixels at a time. To select a particular object:\n",
    "\n",
    "1. Find the label value associated with the object.\n",
    "2. Create a mask of matching pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label the image \"mask\"\n",
    "labels, nlabels = ndi.label(mask)\n",
    "\n",
    "# Select brain label\n",
    "brain_val = 2                                           # 2 is the label for the brain (see plot above)\n",
    "brain_mask = np.where(labels == brain_val, 1, np.nan)   # create brain mask\n",
    "\n",
    "# Overlay selected label\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "axes[0].imshow(im, cmap='gray')\n",
    "axes[0].set_title('original', fontweight =\"bold\")\n",
    "axes[1].imshow(im, cmap='gray')\n",
    "axes[1].imshow(brain_mask, cmap='rainbow', alpha=0.6)\n",
    "axes[1].set_title('with segmentation', fontweight =\"bold\")\n",
    "format_and_render_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Objects\n",
    "Extracting objects from the original image eliminates unrelated pixels and provides new images that can be analyzed independently.\n",
    "\n",
    "The key is to crop images so that they only include the object of interest. The range of pixel indices that encompass the object is the bounding box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_mask=brain_mask.astype(np.int64)\n",
    "\n",
    "# Find bounding box\n",
    "bboxes =ndi.find_objects(brain_mask)                # returns a list of tuples, each tuple has 3 slices\n",
    "print('Number of objects:', len(bboxes))            # number of objects found\n",
    "print('Indices for first box:', bboxes[0])          # print indices for first box\n",
    "\n",
    "# Crop to index 0\n",
    "im_brain = im[bboxes[0]]                            # crop the original image to the bounding box\n",
    "\n",
    "# Plot the cropped image\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "axes[0].imshow(im, cmap='gray')\n",
    "axes[0].set_title('original', fontweight =\"bold\")\n",
    "axes[1].imshow(im_brain, cmap='gray')\n",
    "axes[1].set_title('cropped', fontweight =\"bold\")\n",
    "format_and_render_plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure Variance\n",
    "SciPy measurement functions allow you to tailor measurements to specific sets of pixels:\n",
    "\n",
    "- Specifying `labels` restricts the mask to non-zero pixels.\n",
    "- Specifying `index` value(s) returns a measure for each label value.\n",
    "\n",
    "For this exercise, calculate the intensity variance of `vol` with respect to different pixel sets. We have provided the 3D segmented image as `labels`: label 1 is the left ventricle and label 2 is a circular sample of tissue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance for all pixels\n",
    "var_all = ndi.variance(vol, labels=None, index=None)            # labels=None means all pixels, index=None means all objects\n",
    "print('All pixels:', var_all)\n",
    "\n",
    "# Variance for labeled pixels\n",
    "var_labels = ndi.variance(vol, labels, index=None)              # labels=labels means only labeled pixels, index=None means all objects\n",
    "print('Labeled pixels:', var_labels)\n",
    "\n",
    "# Variance for each object\n",
    "var_objects = ndi.variance(vol, labels, index=[1,2])            # labels=labels means only labeled pixels, index=[1,2] means only objects 1 and 2\n",
    "print('Brain matter:', var_objects[0])\n",
    "print('Other tissue:', var_objects[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate Histograms\n",
    "A poor tissue segmentation includes multiple tissue types, leading to a wide distribution of intensity values and more variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create histograms for selected pixels\n",
    "hist1 = ndi.histogram(vol, min=0, max=255, bins=256)\n",
    "hist2 = ndi.histogram(vol, 0, 255, 256, labels=labels)\n",
    "hist3 = ndi.histogram(vol, 0, 255, 256, labels=labels, index=1)\n",
    "\n",
    "\n",
    "# Plot the histogram and CDF\n",
    "fig, axes = plt.subplots(3, 1, sharex=True)                 # sharex=True shares the x-axis between the top and bottom subplot\n",
    "axes[0].plot(hist1 / hist1.sum(), label='All pixels')\n",
    "axes[1].plot(hist2 / hist2.sum(), label='All labeled pixels')\n",
    "axes[2].plot(hist3 / hist3.sum(), label='Brain matter')\n",
    "format_and_render_plot(axis=True, legend=True)              # axis=True turns on axis grids for the plot; legend=True turns on the legend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Distance\n",
    "A distance transformation calculates the distance from each pixel to a given point, usually the nearest background pixel. This allows you to determine which points in the object are more interior and which are closer to edges.\n",
    "\n",
    "In this exercise, use the Euclidian distance transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate distances\n",
    "brain = np.where(labels == 2, 1, 0)                                             # create brain mask\n",
    "dists = ndi.distance_transform_edt(brain, sampling=vol.meta['sampling'][1:3])   # calculate distances\n",
    "\n",
    "# Report on distances\n",
    "print('Max distance (mm):', ndi.maximum(dists))\n",
    "print('Max location:', ndi.maximum_position(dists))\n",
    "\n",
    "# Plot overlay of distances\n",
    "overlay = np.where(dists > 0, dists, np.nan)                                    # create overlay\n",
    "\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "axes[0].imshow(im, cmap='gray')\n",
    "axes[0].set_title('original', fontweight =\"bold\")\n",
    "axes[1].imshow(im, cmap='gray')\n",
    "axes[1].imshow(overlay, cmap='hot', alpha=0.75)\n",
    "axes[1].set_title('with distances', fontweight =\"bold\")\n",
    "format_and_render_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Center-Of-Mass (COM)\n",
    "The distance transformation reveals the most embedded portions of an object. On the other hand, `ndi.center_of_mass()` returns the coordinates for the center of an object.\n",
    "\n",
    "The \"mass\" corresponds to intensity values, with higher values pulling the center closer to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract centers of mass for objects 1 and 2\n",
    "coms = ndi.center_of_mass(vol, labels, index=[1,2])\n",
    "print('Label 1 center:', coms[0])\n",
    "print('Label 2 center:', coms[1])\n",
    "\n",
    "# Add marks to plot\n",
    "for c0, c1, c2 in coms:\n",
    "    plt.scatter(c2, c1, s=100, marker='o')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
