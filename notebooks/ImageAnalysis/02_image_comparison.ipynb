{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration of Image Comparison\n",
    "This notebook discusses basics of registration, resampling, and image comparison.\n",
    "\n",
    "This demo is a jupyter notebook, i.e. intended to be run step by step.\n",
    "\n",
    "Author: Eric Einspänner\n",
    "<br>\n",
    "Contributor: Nastaran Takmilhomayouni\n",
    "\n",
    "First version: 6th of July 2023\n",
    "\n",
    "\n",
    "Copyright 2023 Clinic of Neuroradiology, Magdeburg, Germany\n",
    "\n",
    "License: Apache-2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "1. [Initial set-up](#Initial-Set-Up)\n",
    "2. [Load image/volume](#Load-the-Image/Volume)\n",
    "3. [Translation](#Translation)\n",
    "    - [Exercise (Translation)](#exercise-translation)\n",
    "    - [Exercise (Translation - difficult)](#exercise-translation---difficult)\n",
    "4. [Rotation](#Rotations)\n",
    "    - [Exercise (Rotation)](#exercise-rotation)\n",
    "5. [Affine Transformation](#Affine-Transformation)\n",
    "6. [Resampling](#Resampling)\n",
    "7. [Interpolation](#Interpolation)\n",
    "8. [MAE](#Mean-Absolute-Error-MAE)\n",
    "9. [SSIM](#Structural-Similarity-SSIM)\n",
    "10. [IoU](#Intersection-of-The-Union-IOU)\n",
    "11. [Testing group differences](#Testing-Group-Differences)\n",
    "12. [Normalizing metrics](#Normalizing-Metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure figures appears inline and animations works\n",
    "# Edit this to \"\"%matplotlib notebook\" when using the \"classic\" jupyter notebook interface\n",
    "%matplotlib widget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports etc\n",
    "import imageio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.ndimage as ndi\n",
    "import matplotlib.pyplot as plt\n",
    "from Utilities.downloaddata import fetch_data as fdata\n",
    "import SimpleITK as sitk\n",
    "import Utilities.gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_and_render_plot():\n",
    "    '''\n",
    "    Custom function to simplify common formatting operations for exercises. Operations include: \n",
    "    1. Turning off axis grids.\n",
    "    2. Calling `plt.tight_layout` to improve subplot spacing.\n",
    "    3. Calling `plt.show()` to render plot.\n",
    "    '''\n",
    "    fig = plt.gcf()\n",
    "    for ax in fig.axes:\n",
    "        ax.axis('off')    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Image/Volume\n",
    "In this chapter, we'll leverage data use data from the OASIS to compare the brains of different populations: young and old, male and female, healthy and diseased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the directory (volume)\n",
    "folder_path = 'Data/Brain/SE000001/MR000000'\n",
    "\n",
    "# Load the volume\n",
    "vol = imageio.volread(folder_path)\n",
    "print(vol.shape)\n",
    "\n",
    "# save the middle slice as separat image\n",
    "middle_slice = vol.shape[0] // 2\n",
    "im = vol[middle_slice,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation\n",
    "Image translation is like shifting or moving an image from one place to another within a picture. Just like sliding a puzzle piece on a table, image translation shifts the whole picture in different directions—left, right, up, or down.\n",
    "\n",
    "The line `xfm = ndi.shift(im, shift=(10, 15))` is the magic. It shifts the brain picture 10 steps to the right and 15 steps down. It's like sliding the brain within the picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate the brain towards the center\n",
    "xfm = ndi.shift(im, shift=(10, 15))\n",
    "\n",
    "# Plot the original and adjusted images\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "axes[0].imshow(im)\n",
    "axes[1].imshow(xfm)\n",
    "format_and_render_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise (Translation)\n",
    "Now move the picture 12 steps to the left and 8 steps up and plot both images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here (the solution is below)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Solution\n",
    "# Translate the brain towards the center\n",
    "xfm = ndi.shift(im, shift=(-12, -8))\n",
    "\n",
    "# Plot the original and adjusted images\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "axes[0].imshow(im)\n",
    "axes[1].imshow(xfm)\n",
    "format_and_render_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise (Translation - difficult)\n",
    "First, find the center point in the image array and the center of mass (COM) of the brain. Then, translate the image to the center.\n",
    "\n",
    "Note: You need the `ndi.center_of_mass()` function to find the COM (x and y coordinate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here (the solution is below)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find image center of mass\n",
    "com = ndi.center_of_mass(im)\n",
    "\n",
    "# Calculate amount of shift needed\n",
    "d0 = 128 - com[0]\n",
    "d1 = 128 - com[1]\n",
    "\n",
    "print(f'COM: {com}, d0: {d0}, d1: {d1}')\n",
    "\n",
    "# Translate the brain towards the center\n",
    "xfm = ndi.shift(im, shift=(d0, d1))\n",
    "\n",
    "# Plot the original and adjusted images\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "axes[0].imshow(im)\n",
    "axes[1].imshow(xfm)\n",
    "format_and_render_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotations\n",
    "In cases where an object is angled or flipped, the image can be rotated. Using `ndi.rotate()`, the image is rotated from its center by the specified degrees from the right horizontal axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotate the shifted image\n",
    "xfm = ndi.rotate(xfm, angle=-30, reshape=False)\n",
    "\n",
    "# Plot the original and transformed images\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "axes[0].imshow(im)\n",
    "axes[1].imshow(xfm)\n",
    "format_and_render_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise (Rotation)\n",
    "First move the image 20 steps to the left and upwards. Then rotate the shifted image counterclockwise by 45°."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here (the solution is below)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Solution\n",
    "# Shift the image towards the center\n",
    "xfm = ndi.shift(im, shift=(-20, -20))\n",
    "\n",
    "# Rotate the shifted image\n",
    "xfm = ndi.rotate(xfm, angle=45, reshape=False)\n",
    "\n",
    "# Plot the original and transformed images\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "axes[0].imshow(im)\n",
    "axes[1].imshow(xfm)\n",
    "format_and_render_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affine Transformation\n",
    "Affine transformation is a way to change the shape, size, and position of an image. It's like using a special set of rules to stretch, shrink, rotate, or skew an image, while keeping its lines straight and parallel.\n",
    "\n",
    "- What is Affine Transformation?\n",
    "\n",
    "It's a mathematical way to adjust images using operations like scaling (changing size), rotation, translation (shifting), and shearing (changing angles).\n",
    "\n",
    "- How Does It Work?\n",
    "\n",
    "Affine transformations use matrix multiplication to alter an image. Each transformation, like scaling or rotating, is represented by a matrix that applies specific changes to the image.\n",
    "\n",
    "![Affine Transformation matrices](../ImageAnalysis/Data/Images/affine_transform.png)\n",
    "\n",
    "Experiment with the values in the matrix and observe the changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the affine transform matrix\n",
    "mat = np.array([[0.8, -0.4, 90], [0.4, 0.8, -6.0], [0, 0, 1]])\n",
    "print(mat)\n",
    "\n",
    "# Apply the affine transform matrix to image data\n",
    "xfm = ndi.affine_transform(im, mat)\n",
    "\n",
    "# Plot the original and transformed images\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "axes[0].imshow(im)\n",
    "axes[1].imshow(xfm)\n",
    "format_and_render_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling\n",
    "Images can be collected in a variety of shapes and sizes. Resampling is a useful tool when these shapes need to be made consistent. Two common applications are:\n",
    "\n",
    "- Downsampling: combining pixel data to decrease size\n",
    "- Upsampling: distributing pixel data to increase size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample image\n",
    "im_dn = ndi.zoom(im, zoom=0.25)\n",
    "im_up = ndi.zoom(im, zoom=4.00)\n",
    "\n",
    "# Plot the images\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "axes[0].imshow(im_dn)\n",
    "axes[1].imshow(im_up)\n",
    "format_and_render_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolation\n",
    "Interpolation is how new pixel intensities are estimated when an image transformation is applied. It is implemented in SciPy using sets of spline functions.\n",
    "\n",
    "Editing the interpolation `order` when using a function such as `ndi.zoom()` modifies the resulting estimate: higher orders provide more flexible estimates but take longer to compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsample \"im\" by a factor of 4\n",
    "up0 = ndi.zoom(im, zoom=512/128, order=0)\n",
    "up5 = ndi.zoom(im, zoom=512/128, order=5)\n",
    "\n",
    "# Print original and new shape\n",
    "print('Original shape:', im.shape)\n",
    "print('Upsampled shape:', up5.shape)\n",
    "\n",
    "# Plot close-ups of the new images\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "axes[0].imshow(up0[128:256, 128:256])\n",
    "axes[1].imshow(up5[128:256, 128:256])\n",
    "format_and_render_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Absolute Error (MAE)\n",
    "Cost functions and objective functions output a single value that summarizes how well two images match.\n",
    "\n",
    "The MAE, for example, summarizes intensity differences between two images, with higher values indicating greater divergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dcm file (image)\n",
    "im1 = im\n",
    "\n",
    "# Apply the affine transform matrix to image data\n",
    "xfm = ndi.shift(im, shift=(-12, -8))\n",
    "im2 = xfm\n",
    "\n",
    "# Calculate image difference\n",
    "err = im1 - im2\n",
    "\n",
    "# Plot the difference\n",
    "fig, axes = plt.subplots(1, 3)\n",
    "axes[0].imshow(im)\n",
    "axes[1].imshow(xfm)\n",
    "axes[2].imshow(err, cmap='seismic', vmin=-200, vmax=200)\n",
    "format_and_render_plot()\n",
    "\n",
    "# Calculate absolute image difference\n",
    "abs_err = np.absolute(im1 - im2)\n",
    "\n",
    "# Plot the difference\n",
    "fig, axes = plt.subplots(1, 3)\n",
    "axes[0].imshow(im)\n",
    "axes[1].imshow(xfm)\n",
    "axes[2].imshow(abs_err, cmap='seismic', vmin=-200, vmax=200)\n",
    "format_and_render_plot()\n",
    "\n",
    "# Calculate mean absolute error\n",
    "mean_abs_err = np.mean(np.abs(im1 - im2))\n",
    "print('MAE:', mean_abs_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structural Similarity (SSIM)\n",
    "The Structural Similarity Index (SSIM) is a metric used to measure the similarity between two images. It evaluates how much one image is structurally similar to another, considering perceived changes in structural information, luminance, and contrast that humans typically notice.\n",
    "\n",
    "- Luminance Comparison: Measures the difference in average luminance (brightness) between the two images.\n",
    "- Contrast Comparison: Evaluates differences in contrast between corresponding image patches.\n",
    "- Structure Comparison: Considers the structural information by comparing similarities in image structures using local mean, standard deviation, and cross-correlation.\n",
    "\n",
    "The SSIM index ranges from -1 to 1. A value of 1 indicates perfect similarity, implying the two images are exactly the same. A value of -1 implies perfect dissimilarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "# Compute SSIM between im and xfm\n",
    "data_range=xfm.max() - xfm.min()\n",
    "ssim_index = ssim(im, xfm, data_range=data_range)\n",
    "\n",
    "print(f'SSIM: {ssim_index}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intersection of The Union (IoU)\n",
    "\n",
    "Another cost function is the IoU. The IoU is the number of pixels filled in both images (the intersection) out of the number of pixels filled in either image (the union)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_of_union(im1, im2):\n",
    "    i = np.logical_and(im1, im2)\n",
    "    u = np.logical_or(im1, im2)\n",
    "    return i.sum() / u.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try some other paramters by yourself\n",
    "xfm = ndi.shift(im, shift=(-10, -10))\n",
    "xfm = ndi.rotate(xfm, angle=-15, reshape=False)\n",
    "intersection_of_union(xfm, im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Group Differences\n",
    "Once measures have been extracted, double-check for dependencies within your data. This is especially true if any image parameters (sampling rate, field of view) might differ between subjects, or you pull multiple measures from a single image.\n",
    "\n",
    "For the final exercises, we have combined demographic and brain volume measures into a pandas DataFrame (df)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load OASIS csv file\n",
    "df = pd.read_csv('Data/Brain/oasis_all_volumes.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print random sample of rows\n",
    "print(df.head())\n",
    "\n",
    "# Print prevalence of Alzheimer's Disease\n",
    "print(df.alzheimers.value_counts())\n",
    "\n",
    "# Print a correlation table excluding non-numeric columns\n",
    "print(df.select_dtypes(include='number').corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the hypothesis that Alzheimer's Disease is characterized by reduced brain volume.\n",
    "\n",
    "We can perform a two-sample t-test between the brain volumes of elderly adults with and without Alzheimer's Disease. In this case, the two population samples are independent from each other because they are all separate subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import independent two-sample t-test\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Select data from \"alzheimers\" and \"typical\" groups\n",
    "brain_alz = df.loc[df.alzheimers == True, 'brain_vol']\n",
    "brain_typ = df.loc[df.alzheimers == False, 'brain_vol']\n",
    "\n",
    "# Perform t-test of \"alz\" > \"typ\"\n",
    "results = ttest_ind(brain_alz, brain_typ)\n",
    "print('t = ', results.statistic)\n",
    "print('p = ', results.pvalue)\n",
    "\n",
    "# Show boxplot of brain_vol differences\n",
    "df.boxplot(column='brain_vol', by='alzheimers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing Metrics\n",
    "We previously saw that there was not a significant difference between the brain volumes of elderly individuals with and without Alzheimer's Disease.\n",
    "\n",
    "But could a correlated measure, such as \"skull volume\" be masking the differences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust `brain_vol` by `skull_vol`\n",
    "df['adj_brain_vol'] = df.brain_vol / df.skull_vol\n",
    "\n",
    "# Select brain measures by group\n",
    "brain_alz = df.loc[df.alzheimers == True, 'adj_brain_vol']\n",
    "brain_typ = df.loc[df.alzheimers == False, 'adj_brain_vol']\n",
    "\n",
    "# Evaluate null hypothesis\n",
    "results = ttest_ind(brain_alz, brain_typ)\n",
    "print('t = ', results.statistic)\n",
    "print('p = ', results.pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Two Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a variety of ways we can overlay two (partially) overlapping images onto each other. The common approaches include:\n",
    "1. Use of alpha blending.\n",
    "2. Use of a checkerboard pattern with the pixel values in adjacent squares/boxes taken from each of the images.\n",
    "3. When the pixel values are scalars (gray scale images), combine the two images in different channels, resulting in a color image.\n",
    "\n",
    "We will start by loading two images whose content luckily overlaps in physical space. Before we can combine the two, we need to resample one of them so that they both occupy the same spatial region. In addition we should also rescale the intensities so that they occupy the same range. In our case we will map them to [0,255], based on the desired windowing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = sitk.ReadImage(fdata(\"training_001_mr_T1.mha\"))\n",
    "img2_original = sitk.ReadImage(fdata(\"training_001_ct.mha\"))\n",
    "img2 = sitk.Resample(img2_original, img1)\n",
    "\n",
    "# Obtain foreground masks for the two images using Otsu thresholding, we use these later on.\n",
    "msk1 = sitk.OtsuThreshold(img1,0,1)\n",
    "msk2 = sitk.OtsuThreshold(img2,0,1)\n",
    "\n",
    "Utilities.gui.MultiImageDisplay(image_list = [img1, img2],                   \n",
    "                      title_list = ['image1', 'image2'],\n",
    "                      figure_size=(9,3));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Having identified the desired intensity range for each of the \n",
    "# images using the GUI above, we use these values to perform intensity windowing and map the intensity values\n",
    "# to [0,255] and cast to 8-bit unsigned int\n",
    "img1_255 = sitk.Cast(sitk.IntensityWindowing(img1, windowMinimum=2, windowMaximum=657, \n",
    "                                             outputMinimum=0.0, outputMaximum=255.0), sitk.sitkUInt8)\n",
    "img2_255 = sitk.Cast(sitk.IntensityWindowing(img2, windowMinimum=-1018, windowMaximum=1126, \n",
    "                                             outputMinimum=0.0, outputMaximum=255.0), sitk.sitkUInt8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
