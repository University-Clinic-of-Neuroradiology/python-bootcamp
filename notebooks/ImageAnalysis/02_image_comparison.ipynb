{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration of Image Comparison\n",
    "This notebook discusses basics of registration, resampling, and image comparison.\n",
    "\n",
    "This demo is a jupyter notebook, i.e. intended to be run step by step.\n",
    "\n",
    "Author: Eric Einspänner\n",
    "<br>\n",
    "Contributor: Nastaran Takmilhomayouni\n",
    "\n",
    "First version: 6th of July 2023\n",
    "\n",
    "\n",
    "Copyright 2023 Clinic of Neuroradiology, Magdeburg, Germany\n",
    "\n",
    "License: Apache-2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "0. [Initial Set-Up for Google Colab](#initial-set-up-for-google-colab)\n",
    "1. [Initial Set-Up (offline)](#initial-set-up-offline)\n",
    "2. [Load image/volume](#Load-the-Image/Volume)\n",
    "3. [Translation](#Translation)\n",
    "    - [Exercise (Translation)](#exercise-translation)\n",
    "    - [Exercise (Translation - difficult)](#exercise-translation---difficult)\n",
    "4. [Rotation](#Rotations)\n",
    "    - [Exercise (Rotation)](#exercise-rotation)\n",
    "5. [Affine Transformation](#Affine-Transformation)\n",
    "6. [Resampling](#Resampling)\n",
    "7. [Interpolation](#Interpolation)\n",
    "8. [MAE](#Mean-Absolute-Error-MAE)\n",
    "9. [SSIM](#Structural-Similarity-SSIM)\n",
    "10. [IoU](#Intersection-of-The-Union-IOU)\n",
    "11. [Combining Two Images](#combining-two-images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Set-Up for Google Colab\n",
    "<u> Execute these code blocks just in Google Colab! </u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q -O - https://github.com/University-Clinic-of-Neuroradiology/python-bootcamp/archive/refs/heads/main.tar.gz | tar -xzf - --strip-components=2 python-bootcamp-main/notebooks/ImageAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from google.colab import output\n",
    "output.enable_custom_widget_manager()\n",
    "\n",
    "sys.path.insert(0,'ImageAnalysis')\n",
    "os.chdir(sys.path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q ipympl numpy matplotlib imageio==2.34 SciPy scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import imageio\n",
    "import scipy.ndimage as ndi\n",
    "from skimage.metrics import structural_similarity as ssim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Set-Up (offline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure figures appears inline and animations works\n",
    "# Edit this to \"\"%matplotlib notebook\" when using the \"classic\" jupyter notebook interface\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports etc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import imageio\n",
    "import scipy.ndimage as ndi\n",
    "from skimage.metrics import structural_similarity as ssim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function `format_and_render_plot()` is just a simplify formatting method for the plots in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_and_render_plot():\n",
    "    '''\n",
    "    Custom function to simplify common formatting operations for exercises. Operations include: \n",
    "    1. Turning off axis grids.\n",
    "    2. Calling `plt.tight_layout` to improve subplot spacing.\n",
    "    3. Calling `plt.show()` to render plot.\n",
    "    '''\n",
    "    fig = plt.gcf()\n",
    "    for ax in fig.axes:\n",
    "        ax.axis('off')    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Image/Volume\n",
    "In this chapter, we'll leverage data use data from the OASIS to compare the brains of different populations: young and old, male and female, healthy and diseased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the directory (volume)\n",
    "folder_path = 'Data/Brain/SE000001'\n",
    "\n",
    "# Load the volume\n",
    "vol = imageio.volread(folder_path, 'DICOM')\n",
    "print(vol.shape)\n",
    "\n",
    "# save the middle slice as separat image\n",
    "middle_slice = vol.shape[0] // 2            # // is floor division\n",
    "im = vol[middle_slice,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation\n",
    "Image translation is like shifting or moving an image from one place to another within a picture. Just like sliding a puzzle piece on a table, image translation shifts the whole picture in different directions—left, right, up, or down.\n",
    "\n",
    "The line `xfm = ndi.shift(im, shift=(10, 15))` is the magic. It shifts the brain picture 10 steps to the right and 15 steps down. It's like sliding the brain within the picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate the brain towards the center\n",
    "xfm = ndi.shift(im, shift=(10, 15))\n",
    "\n",
    "# Plot the original and adjusted images\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "axes[0].imshow(im, cmap='gray')\n",
    "axes[0].set_title('original', fontweight =\"bold\")\n",
    "axes[1].imshow(xfm, cmap='gray')\n",
    "axes[1].set_title('translated', fontweight =\"bold\")\n",
    "format_and_render_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise (Translation)\n",
    "Now move the picture 12 steps to the left and 8 steps up and plot both images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here (the solution is below)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Solution\n",
    "# Translate the brain towards the center\n",
    "xfm = ndi.shift(im, shift=(-12, -8))\n",
    "\n",
    "# Plot the original and adjusted images\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "axes[0].imshow(im, cmap='gray')\n",
    "axes[0].set_title('original', fontweight =\"bold\")\n",
    "axes[1].imshow(xfm, cmap='gray')\n",
    "axes[1].set_title('translated', fontweight =\"bold\")\n",
    "format_and_render_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise (Translation - difficult)\n",
    "First, find the center point in the image array and the center of mass (COM) of the brain. Then, translate the image to the center.\n",
    "\n",
    "Note: You need the `ndi.center_of_mass()` function to find the COM (x and y coordinate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here (the solution is below)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find image center of mass\n",
    "com = ndi.center_of_mass(im)\n",
    "\n",
    "# Calculate amount of shift needed\n",
    "d0 = 128 - com[0]\n",
    "d1 = 128 - com[1]\n",
    "\n",
    "print(f'COM: {com}, d0: {d0}, d1: {d1}')\n",
    "\n",
    "# Translate the brain towards the center\n",
    "xfm = ndi.shift(im, shift=(d0, d1))\n",
    "\n",
    "# Plot the original and adjusted images\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "axes[0].imshow(im, cmap='gray')\n",
    "axes[0].set_title('original', fontweight =\"bold\")\n",
    "axes[1].imshow(xfm, cmap='gray')\n",
    "axes[1].set_title('translated', fontweight =\"bold\")\n",
    "format_and_render_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotations\n",
    "In cases where an object is angled or flipped, the image can be rotated. Using `ndi.rotate()`, the image is rotated from its center by the specified degrees from the right horizontal axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotate the shifted image\n",
    "xfm = ndi.rotate(xfm, angle=-30, reshape=False)\n",
    "\n",
    "# Plot the original and transformed images\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "axes[0].imshow(im, cmap='gray')\n",
    "axes[0].set_title('original', fontweight =\"bold\")\n",
    "axes[1].imshow(xfm, cmap='gray')\n",
    "axes[1].set_title('rotated', fontweight =\"bold\")\n",
    "format_and_render_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise (Rotation)\n",
    "First move the image 20 steps to the left and upwards. Then rotate the shifted image counterclockwise by 45°."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here (the solution is below)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Solution\n",
    "# Shift the image towards the center\n",
    "xfm = ndi.shift(im, shift=(-20, -20))\n",
    "\n",
    "# Rotate the shifted image\n",
    "xfm = ndi.rotate(xfm, angle=45, reshape=False)\n",
    "\n",
    "# Plot the original and transformed images\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "axes[0].imshow(im, cmap='gray')\n",
    "axes[0].set_title('original', fontweight =\"bold\")\n",
    "axes[1].imshow(xfm, cmap='gray')\n",
    "axes[1].set_title('translated + rotated', fontweight =\"bold\")\n",
    "format_and_render_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affine Transformation\n",
    "Affine transformation is a way to change the shape, size, and position of an image. It's like using a special set of rules to stretch, shrink, rotate, or skew an image, while keeping its lines straight and parallel.\n",
    "\n",
    "- What is Affine Transformation?\n",
    "\n",
    "It's a mathematical way to adjust images using operations like scaling (changing size), rotation, translation (shifting), and shearing (changing angles).\n",
    "\n",
    "- How Does It Work?\n",
    "\n",
    "Affine transformations use matrix multiplication to alter an image. Each transformation, like scaling or rotating, is represented by a matrix that applies specific changes to the image.\n",
    "\n",
    "![Affine Transformation matrices](../ImageAnalysis/Data/Images/affine_transform.png)\n",
    "\n",
    "Experiment with the values in the matrix and observe the changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the affine transform matrix\n",
    "mat = np.array([[0.8, -0.4, 90], [0.4, 0.8, -6.0], [0, 0, 1]])\n",
    "print(mat)\n",
    "\n",
    "# Apply the affine transform matrix to image data\n",
    "xfm = ndi.affine_transform(im, mat)\n",
    "\n",
    "# Plot the original and transformed images\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "axes[0].imshow(im, cmap='gray')\n",
    "axes[0].set_title('original', fontweight =\"bold\")\n",
    "axes[1].imshow(xfm, cmap='gray')\n",
    "axes[1].set_title('transformed', fontweight =\"bold\")\n",
    "format_and_render_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling\n",
    "Images can be collected in a variety of shapes and sizes. Resampling is a useful tool when these shapes need to be made consistent. Two common applications are:\n",
    "\n",
    "- Downsampling: combining pixel data to decrease size\n",
    "- Upsampling: distributing pixel data to increase size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample image\n",
    "im_dn = ndi.zoom(im, zoom=0.25)\n",
    "im_up = ndi.zoom(im, zoom=4.00)\n",
    "\n",
    "# Plot the images\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "axes[0].imshow(im_dn, cmap='gray')\n",
    "axes[0].set_title('downsampled', fontweight =\"bold\")\n",
    "axes[1].imshow(im_up, cmap='gray')\n",
    "axes[1].set_title('upsampled', fontweight =\"bold\")\n",
    "format_and_render_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolation\n",
    "Interpolation is how new pixel intensities are estimated when an image transformation is applied. It is implemented in SciPy using sets of spline functions.\n",
    "\n",
    "Editing the interpolation `order` when using a function such as `ndi.zoom()` modifies the resulting estimate: higher orders provide more flexible estimates but take longer to compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsample \"im\" by a factor of 4\n",
    "up0 = ndi.zoom(im, zoom=512/128, order=0)\n",
    "up5 = ndi.zoom(im, zoom=512/128, order=5)\n",
    "\n",
    "# Print original and new shape\n",
    "print('Original shape:', im.shape)\n",
    "print('Upsampled shape:', up5.shape)\n",
    "\n",
    "# Plot close-ups of the new images\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "axes[0].imshow(up0[128:256, 128:256], cmap='gray')\n",
    "axes[0].set_title('no interpolation', fontweight =\"bold\")\n",
    "axes[1].imshow(up5[128:256, 128:256], cmap='gray')\n",
    "axes[1].set_title('with interpolation', fontweight =\"bold\")\n",
    "format_and_render_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Absolute Error (MAE)\n",
    "Cost functions and objective functions output a single value that summarizes how well two images match.\n",
    "\n",
    "The MAE, for example, summarizes intensity differences between two images, with higher values indicating greater divergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dcm file (image)\n",
    "im1 = im\n",
    "\n",
    "# Apply the affine transform matrix to image data\n",
    "xfm = ndi.shift(im, shift=(-12, -8))\n",
    "im2 = xfm\n",
    "\n",
    "# Calculate image difference\n",
    "err = im1 - im2\n",
    "\n",
    "# Plot the difference\n",
    "fig, axes = plt.subplots(1, 3)\n",
    "axes[0].imshow(im1, cmap='gray')\n",
    "axes[0].set_title('original', fontweight =\"bold\")\n",
    "axes[1].imshow(im2, cmap='gray')\n",
    "axes[1].set_title('shifted', fontweight =\"bold\")\n",
    "axes[2].imshow(err, cmap='seismic', vmin=-200, vmax=200)\n",
    "axes[2].set_title('error map', fontweight =\"bold\")\n",
    "format_and_render_plot()\n",
    "\n",
    "# Calculate absolute image difference\n",
    "abs_err = np.absolute(im1 - im2)\n",
    "\n",
    "# Plot the difference\n",
    "fig, axes = plt.subplots(1, 3)\n",
    "axes[0].imshow(im1, cmap='gray')\n",
    "axes[0].set_title('original', fontweight =\"bold\")\n",
    "axes[1].imshow(im2, cmap='gray')\n",
    "axes[1].set_title('shifted', fontweight =\"bold\")\n",
    "axes[2].imshow(abs_err, cmap='seismic', vmin=-200, vmax=200)\n",
    "axes[2].set_title('error map (absolute)', fontweight =\"bold\")\n",
    "format_and_render_plot()\n",
    "\n",
    "# Calculate mean absolute error\n",
    "mean_abs_err = np.mean(np.abs(im1 - im2))\n",
    "print('MAE:', mean_abs_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structural Similarity (SSIM)\n",
    "The Structural Similarity Index (SSIM) is a metric used to measure the similarity between two images. It evaluates how much one image is structurally similar to another, considering perceived changes in structural information, luminance, and contrast that humans typically notice.\n",
    "\n",
    "- Luminance Comparison: Measures the difference in average luminance (brightness) between the two images.\n",
    "- Contrast Comparison: Evaluates differences in contrast between corresponding image patches.\n",
    "- Structure Comparison: Considers the structural information by comparing similarities in image structures using local mean, standard deviation, and cross-correlation.\n",
    "\n",
    "The SSIM index ranges from -1 to 1. A value of 1 indicates perfect similarity, implying the two images are exactly the same. A value of -1 implies perfect dissimilarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute SSIM between im and xfm\n",
    "data_range=xfm.max() - xfm.min()\n",
    "ssim_index = ssim(im, xfm, data_range=data_range)\n",
    "\n",
    "print(f'SSIM: {ssim_index}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intersection of The Union (IoU)\n",
    "\n",
    "Another cost function is the IoU. The IoU is the number of pixels filled in both images (the intersection) out of the number of pixels filled in either image (the union)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_of_union(im1, im2):\n",
    "    i = np.logical_and(im1, im2)\n",
    "    u = np.logical_or(im1, im2)\n",
    "    return i.sum() / u.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try some other paramters by yourself\n",
    "xfm = ndi.shift(im, shift=(-10, -10))\n",
    "xfm = ndi.rotate(xfm, angle=-15, reshape=False)\n",
    "intersection_of_union(xfm, im)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
