{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project\n",
    "For this project, let's assume that we have measured the brain volumes for all 400 images in the OASIS dataset and stored them in a csv file. We have also access to all image data sets.\n",
    "\n",
    "This demo is a jupyter notebook, i.e. intended to be run step by step.\n",
    "\n",
    "Author: Eric Einsp√§nner\n",
    "<br>\n",
    "Contributor: Nastaran Takmilhomayouni\n",
    "\n",
    "First version: 6th of July 2023\n",
    "\n",
    "Copyright 2023 Clinic of Neuroradiology, Magdeburg, Germany\n",
    "\n",
    "License: Apache-2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project description - Part I\n",
    "For this project part we are using the data stored in a csv file.\n",
    "\n",
    "With this data, we want to answer some crucial questions:\n",
    "- ...\n",
    "- ...\n",
    "\n",
    "\n",
    "For this question, we can use a two-sample t-test. We will test the null hypothesis that the mean brain volumes shrinks due to Alzheimer's. The likelihood of the null hypothesis being true is assessed by calculating the t-statistic. If the magnitude of t is very far from 0, then we can reject the null hypothesis that the groups are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure figures appears inline and animations works\n",
    "# Edit this to \"\"%matplotlib notebook\" when using the \"classic\" jupyter notebook interface\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to change filepaths\n",
    "from pathlib import Path\n",
    "\n",
    "# We set up matplotlib and the display function\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "# import numpy, pandas, pydicom and ...\n",
    "# ... YOUR CODE FOR TASK 1 ...\n",
    "\n",
    "import pydicom\n",
    "import nibabel as nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Import and read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load OASIS csv file\n",
    "df = # ... YOUR CODE FOR TASK 2 ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Check the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first five rows of the table\n",
    "print(# ... YOUR CODE FOR TASK 3 ...)\n",
    "\n",
    "# Print prevalence of Alzheimer's Disease\n",
    "print(# ... YOUR CODE FOR TASK 3 ...)\n",
    "\n",
    "# Print a correlation table excluding non-numeric columns\n",
    "print(# ... YOUR CODE FOR TASK 3 ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Testing Group Differences\n",
    "Let's test the hypothesis that Alzheimer's Disease is characterized by reduced brain volume. To run the t-test, we need the brain volumes for all patients with diagnosed Alzheimer's and without in our sample. Select the 'alzheimers' values with `df.loc`, then specifying the column with \"brain volume\" values. For the healthy cohort, we change the selected value to 'False'. To run the t-test, import the `ttest_ind()` function from SciPy's stats module. Then, pass the two vectors as our first and second populations. The results object contains the test statistic and the p-value. The p-value corresponds to the probability that the null hypothesis is true.\n",
    "\n",
    "In this case, the two population samples are independent from each other because they are all separate subjects.\n",
    "\n",
    "For this exercise, use the OASIS dataset (`df`) and `ttest_ind` to evaluate the hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import independent two-sample t-test\n",
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better understand the function `ttest_ind` try to get more information about `ttest_ind` with the `help()` function. Which parameters does the function need? What is the output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(# ... YOUR CODE FOR TASK 4 ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use DataFrame operations to extract brain volume data for Alzheimer's and typical groups for the column `brain_vol`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select data from \"alzheimers\" and \"typical\" groups\n",
    "brain_alz = # ... YOUR CODE FOR TASK 4 ...\n",
    "brain_typ = # ... YOUR CODE FOR TASK 4 ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now perform a two-sample t-test between the brain volumes of elderly adults with and without Alzheimer's Disease. Using `results.statistic` and `results.pvalue` as your guide, answer the question: Is there strong evidence that Alzheimer's Disease is marked by smaller brain size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform t-test of \"alz\" > \"typ\"\n",
    "results = ttest_ind(# ... YOUR CODE FOR TASK 4 ...)\n",
    "print(# ... YOUR CODE FOR TASK 4 ...)\n",
    "print(# ... YOUR CODE FOR TASK 4 ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution: There is some evidence for decreased brain volume in individuals with Alzheimer's Disease. Since the p-value for this t-test is greater than 0.05, we would not reject the null hypothesis that states the two groups are equal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the distribution of brain volumes based on whether individuals have Alzheimer's disease or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show boxplot of brain_vol differences\n",
    "df.boxplot(# ... YOUR CODE FOR TASK 4 ...)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Normalizing metrics\n",
    "We previously saw that there was not a significant difference between the brain volumes of elderly individuals with and without Alzheimer's Disease. To account for this potential confound, we can normalize brain volume with respect to skull size by calculating the brain to skull ratio.\n",
    "\n",
    "But could a correlated measure, such as \"skull volume\" be masking the differences?\n",
    "\n",
    "For this exercise, calculate a new test statistic for the comparison of brain volume between groups, after adjusting for the subject's skull size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust `brain_vol` by `skull_vol`\n",
    "df['adj_brain_vol'] = # ... YOUR CODE FOR TASK 5 ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use DataFrame operations to extract brain volume data for Alzheimer's and typical groups for the new column `adj_brain_vol` and perform a two-sample t-test between the brain volumes of elderly adults with and without Alzheimer's Disease. The statistics and the p-value would be interesting here (print statistic and p value).\n",
    "\n",
    "Using `results.statistic` and `results.pvalue` as your guide, answer the question: Is there strong evidence that Alzheimer's Disease is marked by smaller brain size, relative to skull size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select brain measures by group\n",
    "brain_alz = df.loc[# ... YOUR CODE FOR TASK 5 ...]\n",
    "brain_typ = df.loc[# ... YOUR CODE FOR TASK 5 ...]\n",
    "\n",
    "# Evaluate null hypothesis\n",
    "results = ttest_ind(# ... YOUR CODE FOR TASK 5 ...)\n",
    "print(# ... YOUR CODE FOR TASK 5 ...)\n",
    "print(# ... YOUR CODE FOR TASK 5 ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution: Yes, reject the null hypothesis! Based on the results.statistic and results.pvalue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project description - Part II\n",
    "For this project part, we are using DICOM images saved in .dcm formats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to make a comparison between two DICOM images. In orther to do that, we can load one DICOM image and by modifying it create a new DICOM image.\n",
    "what you can do is to load one OASIS dataset. \n",
    "Try to generate a new dataset by :\n",
    "<br>\n",
    "    1-changing the scan day\n",
    "<br>\n",
    "    2-applying one manual modification ( affine transformation, DICOM header modification)\n",
    "<br>\n",
    "At the end you'll have two datasets of one patient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Load both datasets\n",
    "Load datasets with pydicom. print and compare DICOM headers.\n",
    "When was the scan date/time of each dataset?\n",
    "<br>\n",
    "you can use pydicom python package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydicom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images stored in the following path\n",
    "file_path = 'files/Day1/MR000000.dcm'\n",
    "dcm = pydicom.dcmread(file_path)\n",
    "\n",
    "file_path2 ='files/Day2/MR000000_2.dcm'\n",
    "dcm2 = pydicom.dcmread(file_path2)\n",
    "\n",
    "# dcm =  # ... YOUR CODE FOR TASK 1 ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our two sets of images were taken on different days. We now need to check this. Take a look at the StudyDate, for example. Are there any other such attributes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study Date of the first image is: 20150114\n",
      "Series Date of the first image is: 20150114\n",
      "Acquisition Date of the first image is: 20150114\n",
      "Content Date of the first image is: 20150114\n",
      "Instance Creation Date of the first image is: 20150114\n",
      "--------------------------------------------------------------\n",
      "Study Date of the first image is: 20150315\n",
      "Series Date of the first image is: 20150315\n",
      "Acquisition Date of the first image is: 20150315\n",
      "Content Date of the first image is: 20150315\n",
      "Instance Creation Date of the first image is: 20150315\n"
     ]
    }
   ],
   "source": [
    "# dcm =  # ... YOUR CODE FOR TASK 1 ...\n",
    "print('Study Date of the first image is:', dcm.StudyDate)\n",
    "print('Series Date of the first image is:', dcm.SeriesDate)\n",
    "print('Acquisition Date of the first image is:', dcm.AcquisitionDate)\n",
    "print('Content Date of the first image is:', dcm.ContentDate)\n",
    "print('Instance Creation Date of the first image is:', dcm.InstanceCreationDate)\n",
    "print('--------------------------------------------------------------')\n",
    "print('Study Date of the first image is:', dcm2.StudyDate)\n",
    "print('Series Date of the first image is:', dcm2.SeriesDate)\n",
    "print('Acquisition Date of the first image is:', dcm2.AcquisitionDate)\n",
    "print('Content Date of the first image is:', dcm2.ContentDate)\n",
    "print('Instance Creation Date of the first image is:', dcm2.InstanceCreationDate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- Convert DICOM to NIfTI\n",
    "In this task we are going to convert DICOM images to NIfTI format and continue working with NIfTI files. We would like to use `dicom2nifti` for this. Search for the documentation and find a suitable function that transfers the folder with the .dcm files into a nii file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dicom2nifti\n",
    "folder_path = 'files/Day1'\n",
    "folder_path2 = 'files/Day2'\n",
    "dicom2nifti.convert_directory(folder_path, folder_path)\n",
    "dicom2nifti.convert_directory(folder_path2, folder_path2)\n",
    "\n",
    "# Solution \n",
    "# loaded DICOM image=# ... YOUR CODE FOR TASK 2 ...\n",
    "# sitk.WriteImage(loaded DICOM image, path to save NIfTI file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to load the transformed nii files with `nibabel`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "imnii = nib.load(folder_path + '201_t2w_tse.nii.gz')\n",
    "imnii2 = nib.load(folder_path2 + '201_t2w_tse.nii.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3- Plot average slice\n",
    "Let's plot the average slice of NIfTI images. In order to do that, you may use nibabel python package.\n",
    "After loading the files you will have a three dimensional matrix. To work with matrices, here taking an average, you can use numpy python package.\n",
    "<br>\n",
    "Finally, plot average slices of two images together using subplot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open nifti image containing all slides as a 3D array\n",
    "img1=#....  \n",
    "img2=#....\n",
    "\n",
    "# average of the 3D array\n",
    "img1_avg_data=#...\n",
    "img2_avg_data=#..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4- Image Comparison\n",
    "Here we can compare two images. In orther to do that, you can select different criterias. Yet, here it's recommended to compare two images using MAE, SSIM and Iod which you have learnt through the bootcamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you can use the following function to better plot the results \n",
    "def format_and_render_plot():\n",
    "    '''\n",
    "    Custom function to simplify common formatting operations for exercises. Operations include: \n",
    "    1. Turning off axis grids.\n",
    "    2. Calling `plt.tight_layout` to improve subplot spacing.\n",
    "    3. Calling `plt.show()` to render plot.\n",
    "    '''\n",
    "    fig = plt.gcf()\n",
    "    for ax in fig.axes:\n",
    "        ax.axis('off')    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE mean absolute error\n",
    "# Calculate image difference\n",
    "err = img1_avg_data - img2_avg_data\n",
    "\n",
    "#SSIM \n",
    "from skimage.metrics import structural_similarity as ssim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5- Image Registration\n",
    "The final step would be to register one image to another. It happens that we need to register two images on eachother to get more information.\n",
    "<br>\n",
    "You can register first image on second image using affine registration offered in dipy.align.transforms python package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.align.imaffine import AffineRegistration\n",
    "affreg = AffineRegistration()\n",
    "transform = AffineTransform3D()\n",
    "affine = affreg.optimize(first image data, second image data, transform, params0=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
